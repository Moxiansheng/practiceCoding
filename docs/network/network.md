# Network

## 1 基本术语

1. **结点 （node）** ：网络中的结点可以是计算机，集线器，交换机或路由器等。

2. **链路（link ）** : 从一个结点到另一个结点的一段物理线路。中间没有任何其他交点。

3. **主机（host）** ：连接在因特网上的计算机。

4. **ISP（Internet Service Provider）** ：因特网服务提供者（提供商）。

5. **IXP（Internet eXchange Point）** ： 互联网交换点 IXP 的主要作用就是允许两个网络直接相连并交换分组，而不需要再通过第三个网络来转发分组。

6. **RFC(Request For Comments)** ：“请求评议”，包含了关于 Internet 几乎所有重要的文字资料。

7. **广域网 WAN（Wide Area Network）** ：任务是通过长距离运送主机发送的数据。

8. **城域网 MAN（Metropolitan Area Network）**：用来将多个局域网进行互连。

9. **局域网 LAN（Local Area Network）** ： 学校或企业大多拥有多个互连的局域网。

10. **个人区域网 PAN（Personal Area Network）** ：在个人工作的地方把属于个人使用的电子设备用无线技术连接起来的网络 。

11. **分组（packet ）** ：因特网中传送的数据单元。由首部 header 和数据段组成。分组又称为包，首部可称为包头。

12. **存储转发（store and forward ）** ：路由器收到一个分组，先检查分组是否正确，并过滤掉冲突包错误。确定包正确后，取出目的地址，通过查找表找到想要发送的输出端口地址，然后将该包发送出去。

    ![](https://camo.githubusercontent.com/511b30999c143af72c96741c999bcc3a861ac1b83d7337f2833212b7d645087d/68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f32303230313032353134323334323136392e676966237069635f63656e746572)

13. **带宽（bandwidth）** ：在计网中，表示在单位时间内从网络中的某一点到另一点所能通过的“最高数据率”。常用来表示网络的通信线路所能传送数据的能力。单位是“比特每秒”，记为 b/s。

14. **吞吐量（throughput ）** ：表示在单位时间内通过某个网络（或信道、接口）的数据量。吞吐量更经常地用于对现实世界中的网络的一种测量，以便知道实际上到底有多少数据量能够通过网络。吞吐量受网络的带宽或网络的额定速率的限制。

15. **时延（time delay）**：

    总时延 = 排队时延 + 处理时延 + 传输时延 + 传播时延

    前三个在路由器中，最后一个在信道中。

## 2 体系结构

![](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/0fa6c237-a909-4e2a-a771-2c5485cd8ce0.png)

## 3 物理层 

**实现比特流通信**		

考虑的是怎样在传输媒体上传输数据比特流，而不是指具体的传输媒体。物理层的作用是尽可能屏蔽传输媒体和通信手段的差异，使数据链路层感觉不到这些差异。

根据信息在传输线上的传送方向，分为以下三种通信方式：

- 单工通信：单向传输
- 半双工通信：双向交替传输
- 全双工通信：双向同时传输

## 4 数据链路层

**实现链路通信**，链路即一个结点到相邻结点的一段物理链路。

### 4.1 三个基本问题

- **封装成帧**

  将网络层传下来的分组添加首部和尾部，用于标记帧的开始和结束。

  首部 **|** IP数据报 **|** 尾部

- **透明传输**

  透明表示一个实际存在的事物看起来好像不存在一样。

  帧使用首部和尾部进行定界，如果帧的数据部分含有和首部尾部相同的内容，那么帧的开始和结束位置就会被错误的判定。需要在数据部分出现首部尾部相同的内容前面插入转义字符。如果数据部分出现转义字符，那么就在转义字符前面再加个转义字符。在接收端进行处理之后可以还原出原始数据。**这个过程透明传输的内容是转义字符，用户察觉不到转义字符的存在。**

- **差错检测**

  数据链路层广泛使用了循环冗余检验（CRC）来检查比特差错。

### 4.2 信道分类

- **广播信道**

  一对多通信，一个节点发送的数据能够被广播信道上所有的节点接收到。

  所有的节点都在同一个广播信道上发送数据，因此需要有专门的控制方法进行协调，避免发生冲突（冲突也叫碰撞）。

  主要有两种控制方法进行协调，一个是使用信道复用技术，一是使用 CSMA/CD 协议。

- **点对点信道**

  一对一通信。

  因为不会发生碰撞，因此也比较简单，使用 PPP 协议进行控制。

### 4.3 常用信道复用技术

1. **频分复用(FDM)** ：所有用户在同样的时间占用不同的带宽资源。
2. **时分复用（TDM）** ：所有用户在不同的时间占用同样的频带宽度（分时不分频）。
3. **统计时分复用 (Statistic TDM)** ：改进的时分复用，能够明显提高信道的利用率。
4. **码分复用(CDM)** ： 用户使用经过特殊挑选的不同码型，因此各用户之间不会造成干扰。这种系统发送的信号有很强的抗干扰能力，其频谱类似于白噪声，不易被敌人发现。
5. **波分复用( WDM)** ：波分复用就是光的频分复用。

### 4.4 PPP协议

​		互联网用户通常需要连接到某个 ISP 之后才能接入到互联网，PPP 协议是用户计算机和 ISP 进行通信时所使用的数据链路层协议。

PPP 的帧格式：

- F 字段为帧的定界符
- A 和 C 字段暂时没有意义
- 协议部分用于表示数据部分的协议类型
- FCS 字段是使用 CRC 的检验序列
- 信息部分的长度不超过 1500

![PPP帧](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/759013d7-61d8-4509-897a-d75af598a236.png)

### 4.5 MAC地址

MAC 地址是链路层地址，长度为 6 字节（48 位），用于唯一标识网络适配器（网卡）。

一台主机拥有多少个网络适配器就有多少个 MAC 地址。例如笔记本电脑普遍存在无线网络适配器和有线网络适配器，因此就有两个 MAC 地址。

![MAC帧](D:\IDEA projects\practiceCoding\docs\network\3b87e950352ac65c18921eccf0f2b21192138afd.jpg)



### 4.6 地址解析协议ARP

- MAC寻址总流程

  - 每台电脑要访问任意一个IP地址，都会先计算对方跟自己是不是在同一个子网
    - 判断是否在同一子网：用自己的子网掩码分别于自己的IP和目标IP进行按位与运算，如果计算出来的结果相同，那就是在同一子网内。
  - 如果是，则在ARP表中查找对方IP地址所对应的MAC地址；如果不是，则在ARP表中查找网关IP地址所对应的MAC地址。
  - 不管是查找谁，如果能找到，就直接用以太网格式封装数据发走；如果没有找到，再用ARP去问，收到Reply后写进ARP表，再用以太网封装。

- **ARP查询流程**

  主机A的IP地址为192.168.1.1，MAC地址为0A-11-22-33-44-01；

  主机B的IP地址为192.168.1.2，MAC地址为0A-11-22-33-44-02；主机B也可代指网关。

  当主机A要与主机B通信时，地址解析协议可以将主机B的IP地址（192.168.1.2）解析成主机B的MAC地址，以下为工作流程：

  - 第1步：根据主机A上的路由表内容，IP确定用于访问主机B的转发IP地址是192.168.1.2。然后A主机在自己的本地ARP缓存中检查主机B的匹配MAC地址。
  - 第2步：如果主机A在ARP缓存中没有找到映射，它将询问192.168.1.2的硬件地址，从而将ARP请求帧广播到本地网络上的所有主机。源主机A的IP地址和MAC地址都包括在ARP请求中。本地网络上的每台主机都接收到ARP请求并且检查是否与自己的IP地址匹配。如果主机发现请求的IP地址与自己的IP地址不匹配，它将丢弃ARP请求。
  - 第3步：主机B确定ARP请求中的IP地址与自己的IP地址匹配，则将主机A的IP地址和MAC地址映射添加到本地ARP缓存中。
  - 第4步：主机B将包含其MAC地址的ARP回复消息直接发送回主机A。
  - 第5步：当主机A收到从主机B发来的ARP回复消息时，会用主机B的IP和MAC地址映射更新ARP缓存。本机缓存是有生存期的，生存期结束后，将再次重复上面的过程。主机B的MAC地址一旦确定，主机A就能向主机B发送IP通信了。

- 工作要素：ARP缓存

  - ARP缓存是个用来储存IP地址和MAC地址的缓冲区，其本质就是一个IP地址-->MAC地址的对应表，表中每一个条目分别记录了网络上其他主机的IP地址和对应的MAC地址。
  - 每一个以太网或令牌环网络适配器都有自己单独的表。当地址解析协议被询问一个已知IP地址节点的MAC地址时，先在ARP缓存中查看，若存在，就直接返回与之对应的MAC地址，若不存在，才发送ARP请求向局域网查询。
  - 为使广播量最小，ARP维护IP地址到MAC地址映射的缓存以便将来使用。ARP缓存可以包含动态和静态项目。
    - 动态项目随时间推移自动添加和删除。每个动态ARP缓存项的潜在生命周期是10分钟。新加到缓存中的项目带有时间戳，若某个项目添加后2分钟内没有再使用，则此项目过期并从ARP缓存中删除；如果某个项目已在使用，则又收到2分钟的生命周期；如果某个项目始终在使用，则会另外收到2分钟的生命周期，一直到10分钟的最长生命周期。
    - 静态项目一直保留在缓存中，直到重新启动计算机为止。

### 4.7 逆向地址解析协议RARR

- 反向地址转换协议（RARP）允许局域网的物理机器从网关服务器的 ARP 表或者缓存上请求其 IP 地址。
- 网络管理员在局域网网关路由器里创建一个表以映射物理地址（MAC）和与其对应的 IP 地址。当设置一台新的机器时，其 RARP 客户机程序需要向路由器上的 RARP 服务器请求相应的 IP 地址。假设在路由表中已经设置了一个记录，RARP 服务器将会返回 IP 地址给机器，此机器就会存储起来以便日后使用。
- 工作流程
  - 发送主机发送一个本地RARP广播，在此广播包中，声明自己的MAC地址且请求任何收到此请求的RARP服务器分配一个IP地址；
  - 本地网段上的RARP服务器收到请求后，检查RARP列表，查找该MAC地址对应的IP地址；
  - 若存在，RARP服务器就给源主机发送一个响应数据包并将此IP地址提供给对方主机使用；
  - 如果不存在，RARP服务器对此不做任何的响应；
  - 源主机收到从RARP服务器的响应信息，就利用得到的IP地址进行通讯；如果一直没有收到RARP服务器的响应信息，表示初始化失败。

### 4.8 ARP与RARP的比较

- 相同点

对于ARP与RARP，request是广播，而reply是单播。

- 不同点
  - 协议的目的完全不同。
  - ARP server在kernel中，而RARP是一个用户进程。

## 5 网络层

**实现主机之间的通信**

因为网络层是整个互联网的核心，因此应当让网络层尽可能简单。网络层向上只提供简单灵活的、**无连接的**、**尽最大努力交互的数据报服务**。

使用 IP 协议，可以把异构的物理网络连接起来，使得在网络层看起来好像是一个统一的网络。

与 IP 协议配套使用的还有三个协议：

- 地址解析协议 ARP（Address Resolution Protocol）
- 网际控制报文协议 ICMP（Internet Control Message Protocol）
- 网际组管理协议 IGMP（Internet Group Management Protocol）

### 5.1 IP地址分类

![IP地址](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/cbf50eb8-22b4-4528-a2e7-d187143d57f7.png)

A128 B64 C32 D16 E8

ABC商用 D多播 E保留

### 5.2 地址解析协议ARP（上一层的)

在通信过程中，IP 数据报的源地址和目的地址始终不变，而 MAC 地址随着链路的改变而改变。

每个主机都有一个 ARP 高速缓存，存有本局域网上各主机和路由器的 IP 地址到 MAC 地址的映射表。

如果主机 A 知道主机 B 的 IP 地址，但是 ARP 高速缓存中没有该 IP 地址到 MAC 地址的映射，此时主机 A 通过广播的方式发送 ARP 请求分组，主机 B 收到该请求后会发送 ARP 响应分组给主机 A 告知其 MAC 地址，随后主机 A 向其高速缓存中写入主机 B 的 IP 地址到 MAC 地址的映射。

### 5.3 网际控制报文协议ICMP

ICMP 是为了更有效地转发 IP 数据报和提高交付成功的机会。它封装在 IP 数据报中，但是不属于高层协议。

- Ping

  Ping 是 ICMP 的一个重要应用，主要用来测试两台主机之间的连通性。通过向目的主机发送 ICMP Echo 请求报文，目的主机收到之后会发送 Echo 回答报文。Ping 会根据时间和成功响应的次数估算出数据包往返时间以及丢包率。

- Traceroute

  用来跟踪一个分组从源点到终点的路径。封装的是无法交付的 UDP 用户数据报，并由目的主机发送终点不可达差错报告报文。最终源主机知道了到达目的主机所经过的路由器 IP 地址以及到达每个路由器的往返时间。

### 5.4 网际组管理协议IGMP

背景
- 主机IP软件需要进行组播扩展，才能使主机能够在本地网络上收发组播分组。但仅靠这一点是不够的，因为跨越多个网络的组播转发必须依赖于路由器。
- 路由器为建立组播转发路由必需了解每个组员在Internet中的分布，这要求主机必须能将其所在的组播组通知给本地路由器，这也是建立组播转发路由的基础。
- 为了完成上述功能，需要组播协议。**组播协议包括组成员管理协议和组播路由协议**。
- 组成员管理协议用于管理组播组成员的加入和离开。
- 组播路由协议负责在路由器之间交互信息来建立组播树。
- **IGMP是前者，是组播路由器用来维护组播组成员信息的协议，运行于主机和组播路由器之间**。

- 在此基础上，本地路由器再与其它组播路由器通信，传播组播组的成员信息，并建立组播路由。这个过程与路由器之间的常规单播路由的传播十分相似。
- **IGMP是TCP/IP中重要标准之一，所有IP组播系统(包括主机和路由器)都需要支持IGMP协议**。

IGMP提供了在转发组播数据包到目的地的最后阶段所需的信息，实现如下**双向的功能**：

- **主机通过IGMP通知路由器希望接收或离开某个特定组播组的信息**。
- **路由器通过IGMP周期性地查询局域网内的组播组成员是否处于活动状态，实现所连网段组成员关系的收集与维护**。

### 5.5 虚拟专用网VPN

VPN 使用公用的互联网作为本机构各专用网之间的通信载体。专用指机构内的主机只与本机构内的其它主机通信；虚拟指好像是专用网，而实际上并不是，它有经过公用的互联网。

### 5.6 网络地址转换NAT

专用网内部的主机使用本地 IP 地址又想和互联网上的主机通信时，可以使用 NAT 来将本地 IP 转换为全球 IP。

### 5.7 路由器

- 结构可从功能划分为：路由选择和分组转发

- 分组转发

  - 三部分组成：交换结构，一组输入端口，一组输出端口
  - 转发流程
    - 从数据报的首部提取目的主机的 IP 地址 D，得到目的网络地址 N。
    - 若 N 就是与此路由器直接相连的某个网络地址，则进行直接交付；
    - 若路由表中有目的地址为 D 的特定主机路由，则把数据报传送给表中所指明的下一跳路由器；
    - 若路由表中有到达网络 N 的路由，则把数据报传送给路由表中所指明的下一跳路由器；
    - 若路由表中有一个默认路由，则把数据报传送给路由表中所指明的默认路由器；
    - 报告转发分组出错。

- 路由选择协议

  路由选择协议都是自适应的，能随着网络通信量和拓扑结构的变化而自适应地进行调整。

  互联网可分为许多较小的自治系统 AS，一个 AS 可使用一种和别的 AS 不同的路由选择协议。

  - 内部网关协议RIP

    RIP 是一种基于距离向量的路由选择协议。距离是指跳数，直接相连的路由器跳数为 1。跳数最多为 15，超过 15 表示不可达。

    RIP 协议实现简单，开销小。但是 RIP 能使用的最大距离为 15，限制了网络的规模。并且当网络出现故障时，要经过比较长的时间才能将此消息传送到所有路由器。

  - 内部网关协议OSPF

    开放表示 OSPF 不受某一家厂商控制，而是公开发表的；最短路径优先表示使用了 Dijkstra 提出的最短路径算法 SPF。

    所有路由器都具有全网的拓扑结构图，并且是一致的。相比于 RIP，OSPF 的更新过程收敛的很快。

  - 外部网关协议BGP

    BGP 只能寻找一条比较好的路由，而不是最佳路由。

    每个 AS 都必须配置 BGP 发言人，通过在两个相邻 BGP 发言人之间建立 TCP 连接来交换路由信息。

### 5.7 IP首部

![IP首部](D:\IDEA projects\practiceCoding\docs\network\20190317101238221.png)

- **版本**

  4bit

  - 0100-IPV4；0110-IPV6
  - 在数据传输时，发送方和接收方的IP版本是一致，如果不是，那么数据包就会被丢弃。

- **首部长度**

  4bit：最小值为0101，即5，每1代表4Byte，因此，Min Length: 20 Byte；最大值为1111，即15，故Max Length: 60 Byte

- **服务类型**

  8bit：3bit的优先权字段（000-111），4bit的TOS（type of service）和1bit未用位但必须置为0

- **总长度**

  16bit：表示IP首部+IP数据部的总长度，单位：Byte，Max Value：65535Byte

  MTU（Max Transport Unit）= Max Value；MSS = MTU - 首部长度

- **标识**

  16bit：IP软件在存储器中维持一个计数器，每产生一个数据报，计数器就加1，并将此值赋给标识字段。但这个“标识”不是序号，因为IP是无连接服务，数据报不存在按序接收的问题。当数据报由于长度超过网络的MTU而必须分片时，这个标识字段的值就被复制到所有的数据报片的标识字段中。相同的标识字段的值使分片后的各数据报片最后能正确地重装成为原来的数据报。

  **同一个数据报的各个分片的标识是一样的**

- **标志**

  3bit：分别为R，D，M

  **R**：标志字段中的第一位是一个保留位，现在还没有使用，可能将来会用到这位

  **D**：标志字段中间的一位是 DF (Don’t fragment)，表示传输的数据不允许分片。一般DF = 1的话，表示数据一次性传输过去，不允许分片。

  **M**：标志字段的最低位是 MF (More fragment)。代表数据是否分片，如果MF位值为1，表示后面还有数据，还没有传输完毕，相当于数据分片，分批次传输，如果MF = 0表示最后一个分片或者只有一个分片。

  **这三位同一时刻只能有一个位的值能设置为1** 即标志为100或010或001

- **片偏移**

  13bit：每次分片传输的数据之间的偏移距离，也就是某分片的数据在原数据中的相对位置，一般偏移以8字节为单位。比如：在网络层传输的ip数据报总长度最大不能超过65535字节，如果超过了，要么对ip数据报进行分片传输，否则将丢弃。

  - 为什么是以8字节为单位？
      它是由IP头部格式中的“总长度（16bit）”和“偏移（13bit）”两个字段所决定的。总长度定义了IP包的最大长度为2^16 =64KB,偏移说明了IP分片时它最多能表示2^13 个偏移单位，这样偏移单位就是总长度除以偏移量得出片偏移单位（即2^16 / 2^13=2^3，即为8字节了）。

  - 因为偏移量是以8字节为偏移单位，对于分片1来说从0字节开始算，偏移量为0 / 8 = 0，对于分片2来说从1400字节开始算，偏移量为1400 / 8 = 175，对于分片3来说是从2800开始算，偏移量为2800 / 8 = 350。

    ![分片偏移](D:\IDEA projects\practiceCoding\docs\network\20190317122527226.png)

    **片偏移为0表示这可能是第一个分片，也有可能是这个数据报文不支持分片**
    另外，这些数据包分片的ip首部大部分都是一样的，因为它们都属于同一数据报文，对于数据进行重组就需要参考片偏移和标识这两个重要的字段，需要注意的是，片偏移是根据某一数据片的开始位置来计算的。

- **生存时间**(Time To Live，简称TTL )

  8bit：表示数据报在网络传输过程中的生存时间，目的是防止无法交付的数据包在网络中出现路由环路，最初是秒作为单位，但为了方便，现在都用“跳数”作为TTL的单位。也就是说数据报每经过一个路由器就是一跳，其TTL值就减 1。当路由器收到数据报文后TTL字段值减1后为0的话，那么该路由器就会把数据报丢弃并向主机A发回一个ICMP超时报文，这种机制有效的防止了路由环路，也就是解决了数据报在路由器之间一直转圈的问题。

- **协议**

  8bit：

  | 常用协议 | 协议字段值 |
  | -------- | ---------- |
  | ICMP     | 1          |
  | IGMP     | 2          |
  | IP       | 4          |
  | TCP      | 6          |
  | EGP      | 8          |
  | IGP      | 9          |
  | UDP      | 17         |
  | IPV6     | 41         |
  | ESP      | 50         |
  | OSPF     | 89         |

- **首部校验和**

  16bit：**只检验数据报的首部部分，并不包括数据部分**，因为数据报每经过一个路由器都要重新计算一下首部校验和（一些字段，如生存时间，标志，片偏移等都可能发生变化），这里不采用 CRC 检验码而采用简单的计算方法，校验数据报在传输过程中是否被篡改或数据报被破坏。

  > 为了计算一份数据报的IP检验和，首先把检验和字段置为0。然后，对首部中每个16bit进行二进制反码求和（整个首部看成是由一串16bit的字组成），结果存在检验和字段中。当收到一份IP数据报后，同样对首部中每个16bit进行二进制反码的求和。由于接受方在计算过程中包含了发送方存在首部中的校验和。因此，如果首部在传输过程中没有发生任何差错，那么接受方计算的结果应该为全1。如果结果不是全1（即检验和错误），那么IP就丢弃收到的数据报。

- **源地址**

  32bit：发送方地址

- **目的地址**

  32bit：接收方地址

- **可选字段**

  IP 首部的可变部分就是一个选项字段，一般用于支持排错、测试以及安全等措施，内容很多。选项字段的长度可变，从 1 个比特到 32个比特不等，取决于所选择的项目，增加首部的可变部分是为了增加 IP 数据报的功能，但这同时也使得IP数据报的首部长度成为可变的。这也就增加了每一个路由器处理数据报的开销，而实际上这些选项很少被使用。

## 6 传输层

### 6.1 TCP

**面向连接**的**可靠**传输协议

- **面向连接**：双方三次握手确定彼此收发功能正常后，分配了资源。For each other。
- **可靠**：每次发送都有确认。声声有回响。

#### 6.1.1 TCP数据包结构

![数据包结构图](https://img-blog.csdnimg.cn/2020072916013649.png)

- **数据偏移**

  占4比特，表示数据开始的地方离TCP段的起始处有多远。实际上就是TCP段首部的长度。由于首部长度不固定，因此数据偏移字段是必要的。数据偏移以32位为长度单位，因此TCP首部的最大长度是60（15*4）个字节。

- **标志位（Flags）**6个

| 字段    | 含义                                                         |
| ------- | ------------------------------------------------------------ |
| URG     | 紧急指针是否有效。为1，表示某一位需要被优先处理              |
| **ACK** | 确认号ack是否有效。为1表示有效                               |
| **PSH** | 提示接收端应用程序立即从TCP缓冲区把数据读走。起到加速传输的效果 |
| **RST** | 要求重新建立连接，复位。为1表示重连                          |
| **SYN** | 请求建立连接，并初始化序列号。只有建立连接时为1，握手完成后置为0 |
| **FIN** | 希望断开连接，为1表示此报文段发送方的数据已发送完毕，并要求释放连接 |

- **序列号seq**：占4个字节，用来标记数据段的顺序，TCP把连接中发送的所有数据字节都编上一个序号，第一个字节的编号由本地**随机产生**（后面ISN讲述）；给字节编上序号后，就给每一个报文段指派一个序号；序列号seq就是这个报文段中的第一个字节的数据编号。

- **确认号ack**：占4个字节，ack序号。表示**期待收到对方下一个报文段的第一个数据字节的序号（seq）**只有标志位ACK=1时，确认序号字段才有效，ack=Seq+1。

- **ISN（Initial Sequence Number）**

$$
ISN = M + F(localhost, localport, remotehost, remoteport)
$$
M：一个计时器，每4ms加1

F：一种Hash算法，如MD5

- **为何采用ISN**

**1.防止同一个连接的不同实例的数据包混淆。**

同一个连接指localhost，localport，remotehost，remoteport不变；不同实例指同一连接的多次连接；若ISN不变，可能会出现上次连接的数据包因过大，延迟等原因，落入下次的实例的接收窗中

**2.防止TCP序列号欺骗**

假设A是服务器，B是拥有特殊权限的客户端，C是攻击者，

第一条消息C冒充B来向服务器A请求建立连接，此时C发出的数据包的IP地址会填写成B的；

第二条消息假设A没有其他手段来验证B，而仅仅根据IP地址判断C发过来的建立连接的请求是B发过来的，因此向B发送SYN+ACK，此时假设B被C进行了DOS攻击或者处于其他异常状态而不能响应第二条消息(如果B处于正常状态会响应一个RST包来重启TCP连接，后面我们讲解RST数据包)；

第三条消息假如C能正确的猜测出A在第二条消息中的ISN，就可以冒充B和A完成三次握手的过程，让A误以为和B建立了连接。接下来C就可以冒充B给A发送一些危险数据或者指令而实现攻击。

- **RST**

RST表示复位，用来异常的关闭连接，在TCP的设计中它是不可或缺的。发送RST包关闭连接时，不必等缓冲区的包都发出去（不像上面的FIN包），直接就丢弃缓存区的包发送RST包。而接收端收到RST包后，也不必发送ACK包来确认。

- **RST攻击**

A和服务器B之间建立了TCP连接，此时C伪造了一个TCP包发给B，使B异常的断开了与A之间的TCP连接，就是RST攻击了。	

- **两种TCP包可以完成攻击**
  - 假定C伪装成A发过去的包，这个包如果是RST包的话，毫无疑问，B将会丢弃与A的缓冲区上所有数据，强制关掉连接。
  - 如果发过去的包是SYN包，那么，B会表示A已经发疯了（与OS的实现有关），正常连接时又来建新连接，B主动向A发个RST包，并在自己这端强制关掉连接。

- **完成攻击的关键因素**
  - 源端口：只有正确的源端口号才能骗过对方，攻击对应的连接，这可能是os随机生成的。
  - 序列号：序列号在AB连接时B的滑动窗口内才有攻击性。

- **SYN FLOOD攻击**（TCP的一个缺陷）

攻击者伪装成真实的IP向服务器发送大量伪造源地址的SYN请求，消耗服务器端的巨量资源，以使其无法为正常用户提供服务。

- **SYN FLOOD防御**

  - cookie源认证：第二次握手的seq=cookie

    ![cookie源认证](D:\IDEA projects\practiceCoding\docs\network\201808221657522)

  - reset认证：第二次握手的ack=cookie，第三次客户端发现ack不对，便RST，seq=cookie

    ![reset认证](D:\IDEA projects\practiceCoding\docs\network\20180822170021584)
  
  - TCP首包丢弃：
  
  1. 接受到syn报文   -> 简单比对该IP是否存在于白名单中:  存在则转发到后端，否则进行第2步
    2. 不存在于白名单中 -> 检查是否是该IP在一定时间段内的首次SYN报文： 不是则进行第3步，是则进行第4步
  3. 不是首次SYN报文 -> 检查是否重传报文： 是重传则转发并加入白名单，不是则丢弃并加入黑名单
    4. 是首次SYN报文  -> 丢弃并等待一段时间以试图接受该IP的SYN重传报文，等待超时则判定为攻击报文加入黑名单。

  - TCP Proxy方案：
  
    首包丢弃方案对用户体验会略有影响，因为丢弃首包重传会增大业务响应时间，有鉴于此发展出了一种更优的TCP Proxy方案。
  
    所有的SYN数据报文由清洗设备接受，按照SYN Cookie方案处理。和设备成功建立了TCP三次握手的IP地址被判定为合法用户加入白名单，由设备伪装真实客户端IP地址再与真实服务器完成三次握手，随后转发数据。而指定时间内没有和设备完成三次握手的IP地址，被判定为恶意IP地址屏蔽一定时间。

#### 6.1.2 三次握手

![三次握手图](https://images2015.cnblogs.com/blog/1159846/201706/1159846-20170605223656153-365910138.png)

- **第三次握手syn=0**
- **为什么是三次?**

**三次握手的目的是建立可靠的通信信道，说到通讯，简单来说就是数据的发送与接收，而三次握手最主要的目的就是双方确认自己与对方的发送与接收是正常的。**

第一次握手：Client 什么都不能确认；Server 确认了对方发送正常，自己接收正常

第二次握手：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：对方发送正常，自己接收正常

第三次握手：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：自己发送、接收正常，对方发送、接收正常

所以***三次握手就能确认双发收发功能都正常，缺一不可***。

三次以上，浪费资源；

两次可能发生已失效的连接请求报文段突然又传送到了B。Client在发送完Syn消息1，这里称作Syn1之后，假设因为网络原因，Syn1并没有到达Server端，这个时候Client端已经超时，Client之后重新发起SYN消息，这里称作Syn2。结果由于网络原因Syn2先到达Server，Server于是与Client基于Syn2建立了连接，结果没过多久Syn1又到达了Server,Server于是关掉了Syn2建立的那条连接，又重新建立了一条连接。对于Client来说新建立的这条连接是早就过时的，所以Client不会在这条连接上发送任何数据，这就导致了Server端长时间收不到数据，Client新的连接被断掉了。

- **三次握手失败了会如何**

这里要看是在那个阶段失败的，Client在发送SYN之后没有收到ACK消息，Client会进行重传，第一次重传时间5.5-6s之间，第二次重传会是24s，不成功还会继续尝试，伯克利系统在超过75s之后，如果还是不成功，会放弃尝试连接。

如果Server没有收到最后的一次Ack消息，同样的，Server也会进行重传第二步的Syn+Ack消息。

- **第二次握手传回了ACK，为什么还要传回SYN**？

接收端传回发送端所发送的ACK是为了告诉客户端，我接收到的信息确实就是你所发送的信号了，这表明从客户端到服务端的通信是正常的。回传SYN是为了建立并确认从服务端到客户端的通信。

- **第三次可以携带数据吗？为何？**

可以。能够发出第三次握手报文的主机，肯定接收到第二次(服务器)握手报文，对吗？因为伪造IP的主机是不会接收到第二次报文的。所以，能够发出第三次握手报文的，应该是合法的用户。尽管服务器侧的状态还没有“established”，接收到第三次握手瞬间，状态就切换为“established”，里面携带的数据按照正常流程走就好。

- **三次握手的第一次可以携带数据吗？为何？**

不可以，三次握手还没有完成。对方难道不可以将数据缓存下来，等握手成功再提交给应用程序？这样会放大SYN FLOOD攻击。如果攻击者伪造了成千上万的握手报文，携带了1K+ 字节的数据，而接收方会开辟大量的缓存来容纳这些巨大数据，内存会很容易耗尽，从而拒绝服务。

- **刚才你提到伪造TCP报文尽管有难度，那有什么办法，可以让接收方检测出TCP报文是伪造的、或被篡改的？ TLS可以做到吗？**

使用TCP的安全选项，option 29，可以让通信双方TCP报文强制有HMAC，只有双方拥有HMAC KEY，也只有通信双方可以生成并校验对方的HMAC，任何第三方都没有办法伪造、或篡改而不被接收方发现。TLS位于TCP之上，不对TCP报文头进行完整性保护，只对应用层数据本身做数据完整性保护，所以TLS并不能保护TCP的安全。RST报文为例，完完全全是一个TCP报文头，没有任何报文体，对吗？没有完整性保护，其实脆弱的很，伪造RST报文是一个有难度，但理论上绝对可行的操作。

- **看到有人说，只看到过TCP状态位为’FIN +ACK’，但从来没有看过状态位只有 ‘FIN’，你应该怎样给他解释？**

RFC793明确规定，除了第一个握手报文SYN除外，其它所有报文必须将ACK= 1。

- **RFC规定的背后肯定有合理性的一面，能否深究一下原因？**

TCP作为一个可靠传输协议，其**可靠性就是依赖于收到对方的数据**，**ACK对方，这样对方就可以释放缓存的数据**，因为对方确信数据已经被接收到了。但TCP报文是在IP网络上传输，丢包是家常便饭，接收方**要抓住一切的机会，**把消息告诉发送方。最方便的方式就是，任何我方发送的TCP报文，都要捎带着ACK状态位。

#### 6.1.3 四次挥手

![四次挥手图](https://imgconvert.csdnimg.cn/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTcwNjA2MDg0ODUxMjcy?x-oss-process=image/format,png)

- **第一次挥手ack=1**

- **四次挥手的过程**

  - 客户端发送了 FIN 连接释放报文之后。
  - 服务器收到了这个报文，回复收到。
  - 服务器进入 CLOSE-WAIT 状态。此状态是为了让服务器端发送还未传送完毕的数据，传送完毕后，服务器会发送 FIN 连接释放报文。
  - 客户端再返回确认。

- **四次挥手的原因**

  - 首先是客户端想断，发送了第一次请求。**（1次）**

  - 服务端收到客户端意愿的时候，根据**TCP可靠传输**，服务器端无论自己想不想断，都要返回一个确认。**（2次）**但服务端的意愿也会产生影响：

    - 自己也想断：那就可以将自己想断的请求合并到对客户端的确认中去，那此时，就成了（伪）三次握手，其实还是四次，只是合并了中间两次为一次。**（3次合并到2次）**
    - 自己不想断：那就不能随着确认消息传达自己想断的请求了，这里需要等到自己想断。
      - 这个时候，就会继续完成自己的工作，然后等到自己也想断了，就发送请求，告诉客户端，我要断开连接了。**（3次）**

    > **想断**：自己的想要的数据已经获取完毕，自己想发的数据也发送完毕，可以进行现占有资源的释放了。
    >
    > **不想断**：自己可能数据还有部分在缓冲区没有读完，或者自己还有数据想要发送但是还没有发送完毕，还不能对自己占据的资源进行释放。

  - 当客户端好不容易既收到服务器对自己想断的确认，同时又收到了服务器想断的请求的时候，就可以发送最后一次确认，确认自己也知道服务器想断掉了。**（4次）**

  - 当服务器收到客户端的确认消息之后，服务器端就会释放资源，那么**TCP的面向连接**就已经是短开了，不过此时，客户端仍未释放资源，而是会转入**TIME-WAIT**阶段。

  - 客户端在TIME-WAIT阶段会等待**2MSL**的时间，若此期间，没有再接收到服务器端的消息，就开始释放资源。至此，整个TCP连接全部结束。

- **CLOSE-WAIT**

  CLOSE-WAIT时间内，服务端可以继续发送数据给客户端，同时通知应用进程关闭

- **TIME-WAIT**

  2MSL，MSL（Message Segment Lifetime）TCP允许不同的实现可以设置不同的MSL值。

  - 确保最后一个确认报文能够到达。如果 B 没收到 A 发送来的确认报文，那么就会重新发送连接释放请求报文，A 等待一段时间就是为了处理这种情况的发生。
  - 等待一段时间是为了让本连接持续时间内所产生的所有报文都从网络中消失，使得下一个新的连接不会出现旧的连接请求报文。

- **如果已经建立了连接，但是客户端突然出现故障了怎么办？**

  TCP还设有一个保活计时器，显然，客户端如果出现故障，服务器不能一直等下去，白白浪费资源。服务器每收到一次客户端的请求后都会重新复位这个计时器，时间通常是设置为2小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75秒发送一次。若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。

#### 6.1.4 滑动窗口

窗口是缓存的一部分，用来暂时存放字节流。发送方和接收方各有一个窗口，接收方通过 TCP 报文段中的窗口字段告诉发送方自己的窗口大小，发送方根据这个值和其它信息设置自己的窗口大小。

发送窗口内的字节都允许被发送，接收窗口内的字节都允许被接收。如果发送窗口左部的字节已经发送并且收到了确认，那么就将发送窗口向右滑动一定距离，直到左部第一个字节不是已发送并且已确认的状态；接收窗口的滑动类似，接收窗口左部字节已经发送确认并交付主机，就向右滑动接收窗口。

如果服务端的反馈设置为0，客户端将不能发送**数据**，但可以发送**无数据**的TCP探测，来检验服务端是否可以继续接收数据了。

#### 6.1.5 可靠传输

1. 应用数据被分割成 TCP 认为最适合发送的数据块。
2. TCP 给发送的每一个包进行编号，接收方对数据包进行排序，把有序数据传送给应用层。
3. **校验和：** TCP 将保持它首部和数据的检验和。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果收到段的检验和有差错，TCP 将丢弃这个报文段和不确认收到此报文段。
4. TCP 的接收端会丢弃重复的数据。
5. **流量控制：** TCP 连接的每一方都有固定大小的缓冲空间，TCP的接收端只允许发送端发送接收端缓冲区能接纳的数据。当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。TCP 使用的流量控制协议是可变大小的滑动窗口协议。 （TCP 利用滑动窗口实现流量控制）
6. **拥塞控制：** 当网络拥塞时，减少数据的发送。
7. **ARQ协议：** 也是为了实现可靠传输的，它的基本原理就是每发完一个分组就停止发送，等待对方确认。在收到确认后再发下一个分组。
8. **超时重传：** 当 TCP 发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段。

#### 6.1.6 **自动重传请求**（Automatic Repeat-reQuest，ARQ）

ARQ是OSI模型中**数据链路层和传输层的错误纠正协议**之一。它通过使用确认和超时这两个机制，在不可靠服务的基础上实现可靠的信息传输。如果发送方在发送后一段时间之内没有收到确认帧，它通常会重新发送。ARQ包括停止等待ARQ协议和连续ARQ协议。

- **停止等待ARQ协议**

  - 发送方：每发完一个分组就停止发送，等待对方确认（回复ACK）。如果过了一段时间（超时时间后），还是没有收到 ACK 确认，说明没有发送成功，需要重新发送，直到收到确认后再发下一个分组。

  - 接收方：收到分组就发送确认。若收到重复分组，就丢弃该分组，但同时还要发送确认；

- **连续ARQ协议**

  - 发送方：维持一个发送窗口，凡位于发送窗口内的分组可以连续发送出去，而不需要等待对方确认。
  - 接收方：一般采用累计确认，对按序到达的最后一个分组发送确认，表明到这个分组为止的所有分组都已经正确收到了。
  - Go-Back-N（回退N）：发送方发送5条消息，中间第三条丢失（3号），这时接收方只能对前两个发送确认。发送方无法知道后三个分组的下落，而只好把后三个全部重传一次。

#### 6.1.7 流量控制

流量控制是为了控制发送方发送速率，保证接收方来得及接收。

接收方发送的确认报文中的窗口字段可以用来控制发送方窗口大小，从而影响发送方的发送速率。将窗口字段设置为 0，则发送方不能发送数据。此时发送方将通过一个无数据的TCP进行询问。

#### 6.1.8 拥塞控制

- 如果网络出现拥塞，分组将会丢失，此时发送方会继续重传，从而导致网络拥塞程度更高。因此当出现拥塞时，应当控制发送方的速率。

- 这一点和流量控制很像，但是出发点不同。**流量控制是为了让接收方能来得及接收，而拥塞控制是为了降低整个网络的拥塞程度。**
- TCP 发送方要维持一个**拥塞窗口(cwnd)** 的状态变量。拥塞控制窗口的大小取决于网络拥塞程度，且动态变化。发送方让自己的**发送窗口取为拥塞窗口和接收方的接受窗口中较小的一个**。

- **慢开始**

  设置ssthresh（慢开始门限）for(cwnd=1;cwnd<ssthresh;cwnd*=2)

- **拥塞避免**

  if(cwnd>=ssthresh) cwnd+=1，如果超时，ssthresh=cwnd/2，重新慢开始

- **快重传与快恢复**

  在发送方，如果收到三个重复确认，那么可以知道下一个报文段丢失，此时执行快重传，立即重传三连重复确认的下一个报文段。

  此时，仅丢失个别报文段，而非网络拥塞。故执行快恢复，令cwnd = ssthresh = cwnd / 2，注意到此时直接进入拥塞避免。

  **慢开始和快恢复的快慢指的是 cwnd 的设定值，而不是 cwnd 的增长速率。慢开始 cwnd 设定为 1，而快恢复 cwnd 设定为 ssthresh。**

### 6.2 UDP

- 用户数据报协议 UDP（User Datagram Protocol）是无连接的，尽最大可能交付，没有拥塞控制，面向报文（对于应用程序传下来的报文不合并也不拆分，只是添加 UDP 首部），支持一对一、一对多、多对一和多对多的交互通信。

- 首部字段只有 8 个字节，包括源端口、目的端口、长度、检验和。12 字节的伪首部是为了计算检验和临时添加的。

  ![UDP](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/d4c3a4a1-0846-46ec-9cc3-eaddfca71254.jpg)

### 6.3 UDP与TCP对比

| 类型         | TCP                                  | UDP                      |
| ------------ | ------------------------------------ | ------------------------ |
| 是否面向连接 | 是                                   | 否                       |
| 传输可靠性   | 可靠                                 | 不可靠                   |
| 传输形式     | 字节流                               | 数据报文段               |
| 传输效率     | 慢                                   | 快                       |
| 所需资源     | 多                                   | 少                       |
| 应用场景     | 要求数据可靠（如文件传输，邮件传输） | 要求速度高（如即时通信） |
| 首部字节     | 20-60                                | 8                        |

## 7 应用层

### 7.1 域名系统DNS

DNS（Domain Name System）将人类可读的域名转换为机器可读的 IP 地址。

#### 7.1.1 本地DNS服务器

本机 -----> 路由器（0,...,n) ----->ISP

- 若路由器数为0，也就是本机直连ISP，那本机DNS服务器就是ISP提供的DNS服务器。
- 若不为0，即本机直连的是路由器，那本地DNS服务器就是路由器(路由器往往携带DNS转发)。
- 所以本地DNS服务器是个抽象的名字，确切是谁看真实连接。

#### 7.1.2 DNS解析域名

1. 向本地DNS服务器询问，若DNS高速缓存中有，就获取并返回；反之转入2
2. 向根(.)DNS服务器询问，找到对应的顶级DNS服务器
3. 向顶级(.com)DNS服务器询问，找到对应的主域名DNS服务器
4. 向主域名(.xxx.com)DNS服务器询问，找到返回，且记录在本地DNS服务器高速缓存中，若最终找不到，返回DNS错误。

#### 7.1.3 DNS优化

- **DNS缓存**

  - 浏览器缓存
  - 系统缓存
  - 路由器缓存
  - ISP服务器缓存
  - 根DNS服务器缓存
  - 顶级DNS服务器缓存
  - 主域名DNS服务器缓存

- **DNS负载均衡**

  ​		DNS返回的IP地址是否每次都一样？如果每次都一样是否说明你请求的资源都位于同一台机器上面，那么这台机器需要多高的性能和储存才能满足亿万请求呢？其实真实的互联网世界背后存在成千上百台服务器，大型的网站甚至更多。但是在用户的眼中，它需要的只是处理他的请求，哪台机器处理请求并不重要。**DNS可以返回一个合适的机器的IP给用户，例如可以根据每台机器的负载量，该机器离用户地理位置的距离等等，这种过程就是DNS负载均衡，又叫做DNS重定向。CDN(Content Delivery Network)**就是利用DNS的重定向技术，DNS服务器会返回一个跟用户最接近的点的IP地址给用户，CDN节点的服务器负责响应用户的请求，提供所需的内容。

- **DNS可以使用TCP协议和UDP协议**

  - **DNS区域传输的时候使用TCP协议**
    - 辅域名服务器会定时（一般3小时）向主域名服务器进行查询以便了解数据是否有变动。如有变动，会执行一次区域传送，进行数据同步。区域传送使用TCP而不是UDP，因为数据同步传送的数据量比一个请求应答的数据量要多得多。
    - TCP是一种可靠连接，保证了数据的准确性。
  - **域名解析时使用UDP协议**
    - 客户端向DNS服务器查询域名，一般返回的内容都不超过512字节，用UDP传输即可。不用经过三次握手，这样DNS服务器负载更低，响应更快。
    - 理论上说，客户端也可以指定向DNS服务器查询时用TCP，但事实上，很多DNS服务器进行配置的时候，仅支持UDP查询。

### 7.2 内容分发网络CDN

> CDN部分内容来源与[知乎](https://www.zhihu.com/question/36514327/answer/1604554133)

- **内容分发网络（Content Delivery Network，简称CDN）**是建立并覆盖在承载网之上，由分布在不同区域的边缘节点服务器群组成的分布式网络。支持多种行业、多种场景内容加速，

#### 7.2.1 CDN处理流程

- 当终端用户（北京）向`www.a.com`下的指定资源发起请求时，首先向LDNS（本地DNS）发起域名解析请求。
- LDNS检查缓存中是否有`www.a.com`的IP地址记录。如果有，则直接返回给终端用户；如果没有，则向授权DNS查询。
- 当授权DNS解析`www.a.com`时，返回域名CNAME `www.a.tbcdn.com`对应IP地址。
- 域名解析请求发送至阿里云DNS调度系统，并为请求分配最佳节点IP地址。
- LDNS获取DNS返回的解析IP地址。
- 用户获取解析IP地址。
- 用户向获取的IP地址发起对该资源的访问请求。
  - 如果该IP地址对应的节点已缓存该资源，则会将数据直接返回给用户，例如，图中步骤7和8，请求结束。
  - 如果该IP地址对应的节点未缓存该资源，则节点向源站发起对该资源的请求。获取资源后，结合用户自定义配置的缓存策略，将资源缓存至节点，例如，图中的北京节点，并返回给用户，请求结束。

从处理流程中可以了解到:

- CDN的加速资源是跟域名绑定的。
- 通过域名访问资源，首先是通过DNS分查找离用户最近的CDN节点（边缘服务器）的IP
- 通过IP访问实际资源时，如果CDN上并没有缓存资源，则会到源站请求资源，并缓存到CDN节点上，这样，用户下一次访问时，该CDN节点就会有对应资源的缓存了。

### 7.3 文件传送协议FTP

FTP 使用 TCP 进行连接，它需要两个连接来传送一个文件：

- 控制连接：服务器打开端口号 21 等待客户端的连接，客户端主动建立连接后，使用这个连接将客户端的命令传送给服务器，并传回服务器的应答。
- 数据连接：用来传送一个文件数据。

根据数据连接是否是服务器端主动建立，FTP 有主动和被动两种模式：

- 主动模式：服务器端主动建立数据连接，其中服务器端的端口号为 20，客户端的端口号随机，但是必须大于 1024，因为 0~1023 是熟知端口号。
- 被动模式：客户端主动建立数据连接，其中客户端的端口号由客户端自己指定，服务器端的端口号随机。

主动模式要求客户端开放端口号给服务器端，需要去配置客户端的防火墙。被动模式只需要服务器端开放端口号即可，无需客户端配置防火墙。但是被动模式会导致服务器端的安全性减弱，因为开放了过多的端口号。

### 7.4 动态主机配置协议DHCP

- DHCP (Dynamic Host Configuration Protocol) 提供了即插即用的连网方式，用户不再需要手动配置 IP 地址等信息。


- DHCP 配置的内容不仅是 IP 地址，还包括子网掩码、网关 IP 地址。

- **DHCP协议采用UDP作为传输协议**，主机通过67号端口发送请求消息到DHCP服务器，DHCP服务器回应应答消息给主机的68号端口。详细的交互过程如下图。
  1. DHCP Client以广播的方式发出DHCP Discover报文。
  2. 所有的DHCP Server都能够接收到DHCP Client发送的DHCP Discover报文，所有的DHCP Server都会给出响应，向DHCP Client发送一个DHCP Offer报文。
  3. DHCP Offer报文中“Your(Client) IP Address”字段就是DHCP Server能够提供给DHCP Client使用的IP地址，且DHCP Server会将自己的IP地址放在“option”字段中以便DHCP Client区分不同的DHCP Server。DHCP Server在发出此报文后会存在一个已分配IP地址的纪录。
  4. DHCP Client只能处理其中的一个DHCP Offer报文，一般的原则是DHCP Client处理最先收到的DHCP Offer报文。 
  5. DHCP Client会发出一个广播的DHCP Request报文，在选项字段中会加入选中的DHCP Server的IP地址和需要的IP地址。
  6. DHCP Server收到DHCP Request报文后，判断选项字段中的IP地址是否与自己的地址相同。如果不相同，DHCP Server不做任何处理只清除相应IP地址分配记录；如果相同，DHCP Server就会向DHCP Client响应一个DHCP ACK报文，并在选项字段中增加IP地址的使用租期信息。 
  7. DHCP Client接收到DHCP ACK报文后，检查DHCP Server分配的IP地址是否能够使用。若可以使用，则DHCP Client成功获得IP地址并根据IP地址使用租期自动启动续延过程；若DHCP Client发现分配的IP地址已经被使用，则DHCP Client向DHCPServer发出DHCP Decline报文，通知DHCP Server禁用这个IP地址，然后DHCP Client开始新的地址申请过程。
  8. DHCP Client在成功获取IP地址后，随时可以通过发送DHCP Release报文释放自己的IP地址，DHCP Server收到DHCP Release报文后，会回收相应的IP地址并重新分配。
     - 在使用租期超过50%时刻处，DHCP Client会以单播形式向DHCP Server发送DHCPRequest报文来续租IP地址。如果DHCP Client成功收到DHCP Server发送的DHCP ACK报文，则按相应时间延长IP地址租期；如果没有收到DHCP Server发送的DHCP ACK报文，则DHCP Client继续使用这个IP地址。
     - 在使用租期超过87.5%时刻处，DHCP Client会以广播形式向DHCP Server发送DHCPRequest报文来续租IP地址。如果DHCP Client成功收到DHCP Server发送的DHCP ACK报文，则按相应时间延长IP地址租期；如果没有收到DHCP Server发送的DHCP ACK报文，则DHCP Client继续使用这个IP地址，直到IP地址使用租期到期时，DHCP Client才会向DHCP Server发送DHCP Release报文来释放这个IP地址，并开始新的IP地址申请过程。
     - 需要说明的是：DHCP客户端可以接收到多个DHCP服务器的DHCPOFFER数据包，然后可能接受任何一个DHCPOFFER数据包，但客户端通常只接受收到的第一个DHCPOFFER数据包。另外，DHCP服务器DHCPOFFER中指定的地址不一定为最终分配的地址，通常情况下，DHCP服务器会保留该地址直到客户端发出正式请求。

### 7.5 远程终端协议TELNET

TELNET 用于登录到远程主机上，并且远程主机上的输出也会返回。

TELNET 可以适应许多计算机和操作系统的差异，例如不同操作系统系统的换行符定义。

### 7.6 电子邮件协议

一个电子邮件系统由三部分组成：用户代理、邮件服务器以及邮件协议。

邮件协议包含发送协议和读取协议，发送协议常用 SMTP，读取协议常用 POP3 和 IMAP。

- SMTP

SMTP 只能发送 ASCII 码，而互联网邮件扩充 MIME 可以发送二进制文件。MIME 并没有改动或者取代 SMTP，而是增加邮件主体的结构，定义了非 ASCII 码的编码规则。

- POP3

POP3 的特点是只要用户从服务器上读取了邮件，就把该邮件删除。但最新版本的 POP3 可以不删除邮件。

- IMAP

IMAP 协议中客户端和服务器上的邮件保持同步，如果不手动删除邮件，那么服务器上的邮件也不会被删除。IMAP 这种做法可以让用户随时随地去访问服务器上的邮件。

### 7.7 常用端口

|        应用        | 应用层协议 | 端口号  | 传输层协议 |            备注             |
| :----------------: | :--------: | :-----: | :--------: | :-------------------------: |
|      域名解析      |    DNS     |   53    |  UDP/TCP   | 长度超过 512 字节时使用 TCP |
|  动态主机配置协议  |    DHCP    |  67/68  |    UDP     |                             |
|  简单网络管理协议  |    SNMP    | 161/162 |    UDP     |                             |
|    文件传送协议    |    FTP     |  20/21  |    TCP     |  控制连接 21，数据连接 20   |
|    远程终端协议    |   TELNET   |   23    |    TCP     |                             |
|   超文本传送协议   |    HTTP    |   80    |    TCP     |                             |
|  简单邮件传送协议  |    SMTP    |   25    |    TCP     |                             |
|    邮件读取协议    |    POP3    |   110   |    TCP     |                             |
|  网际报文存取协议  |    IMAP    |   143   |    TCP     |                             |
| 安全超文本传送协议 |   HTTPS    |   443   |    TCP     |                             |

### 7.8 Socket

- **Socket** ： **TCP 用主机的 IP 地址加上主机上的端口号作为 TCP 连接的端点。**

- **Socket四元组** ：**可以唯一标识一个Socket**

  **（源IP，源端口，目标IP，目标端口）**

- 进程发生socket连接，传输数据流程

  - 将待传出的数据从应用进程缓冲区复制到内核缓冲区
  - 通过内核，借助网络端口，传入网络
  - Socket网络连接传输
  - 数据从网络中到达，复制到内核中的某个缓冲区
  - 把数据从内核缓冲区复制到应用进程缓冲区

#### 7.8.1 Socket网络传输

- **服务端监听**

  - **socket()** -----> **创建**一个socket

  - **bind()** -----> 把上一步创建的socket和本机IP，Port**绑定**

  - **listen()** -----> 启动socket**监听**，等待客户端请求

    --------------- 这三步创建出了一个监听socket ---------------

  - **accept()** -----> 监听到客户端请求，返回一个用于**连接**内传输数据的socket

    --------------- 此处返回连接socket，不是监听socket ---------------

  - **read()/write()** -----> **传输**数据，socket io，可通过管道

  - **close()** -----> **关闭**连接socket

    --------------- 这两步是在连接socket内操作 ---------------

- **客户端请求**
  - **socket()** -----> **创建**一个socket
  - **bind()** -----> 将上一步创建的socket和本机IP，本机Port，目标IP，目标端口**绑定**
  - **connect()** -----> 主动**请求**服务端的监听socket
  - **read()/write()** -----> **传输**数据，socket io，可通过管道
  - **close()** -----> **关闭**连接socket
- 客户端从头至尾只有一个socket，负责主动连接和数据传输。
- 服务端则有两种socket，分别是**监听socket**和**连接socket**
  - 监听socket就是最初创建的那个socket，当监听到请求后，**accept()**就会返回一个新的socket，这个就是连接socket。
  - 连接socket会专注于处理*导致创建自己的那次请求连接*的数据传输，相当于专职负责这一个连接业务，当传输结束后，**close()**关闭的是连接socket。
- 因为一次accept产生一个连接socket，所以**同一个端口号下，产生了多个socket连接**。
  - 一个端口号只能分配给一个进程使用，但是一个进程内可以创建多个TCP连接和UDP，这些TCP和UDP可以共用一个端口号。
  - 不同的socket可以共用一个端口，是因为socket通过五元组标识，其中本机IP，本机Port，协议都是相同的，但不同客户端发起的不同连接拥有不同的IP，端口也可能不同。因为五元组不同，可以在一个端口号内标识多个socket。

```java
		// 验证监听socket和连接socket是同一个端口        
		// 初始设置本机port 10001
		... // 已创建和绑定serverSocket
        socket = serverSocket.accept(); // serverSocket返回新连接socket
        System.out.println(serverSocket.getLocalPort()); // 监听port 输出10001
        System.out.println(socket.getLocalPort()); // 连接port 输出10001
```

#### 7.8.2 数据内核传输

#### 7.8.2.1 阻塞式I/O

- 应用进程被阻塞，直到数据从内核缓冲区复制到应用进程缓冲区中才返回。
- 在阻塞的过程中，其它应用进程还可执行，因此阻塞不意味着整个操作系统都被阻塞。因为其它应用进程还可以执行，所以不消耗 CPU 时间，这种模型的 CPU 利用率会比较高。

![阻塞式I/O](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/1492928416812_4.png)

#### 7.8.2.2 非阻塞式I/O

- 应用进程执行系统调用之后，内核返回一个错误码。应用进程可以继续执行，但是需要不断的执行系统调用来获知 I/O 是否完成，这种方式称为轮询（polling）。
- 由于 CPU 要处理更多的系统调用，因此这种模型的 CPU 利用率比较低。

![非阻塞式I/O](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/1492929000361_5.png)

#### 7.8.2.3 I/O复用（依旧是NIO）

- 使用 select 或者 poll 等待数据，且可以等待多个套接字中的任一个变为可读。这一过程会被阻塞，当某一个套接字可读时返回，之后再使用 recvfrom 把数据从内核复制到进程中。
- 它让单个进程具有处理多 I/O 事件的能力。又被称为 Event Driven I/O，即**事件驱动 I/O**。
- 相比于多进程和多线程技术，I/O 复用不需要进程线程创建和切换的开销，系统开销更小。

![I/O复用](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/1492929444818_6.png)

- **select**

  select 允许应用程序监视一组文件描述符，等待一或多个描述符为就绪状态，完成 I/O 操作。

- **poll**

  poll 的功能与 select 类似，也是等待一组描述符中的一个成为就绪状态。

- **select VS poll**

  - 功能

    - select 会修改描述符，而 poll 不会；
    - select 的描述符类型使用数组实现，FD_SETSIZE 大小默认为 1024，因此默认只能监听少于 1024 个描述符。如果要监听更多描述符的话，需要修改 FD_SETSIZE 之后重新编译；而 poll 没有描述符数量的限制；
    - poll 提供了更多的事件类型，并且对描述符的重复利用上比 select 高。
    - 如果一个线程对某个描述符调用了 select 或者 poll，另一个线程关闭了该描述符，会导致调用结果不确定。

  - 速度

    select和poll速度都慢，每次调用都需将全部描述符从应用进程缓冲区复制到内核缓冲区。

  - 可移植性

    几乎所有的系统都支持 select，但是只有比较新的系统支持 poll。

- **epoll**

  - epoll_ctl() 用于向内核注册新的描述符或者是改变某个文件描述符的状态。已注册的描述符在内核中会被维护在一棵红黑树上，通过回调函数内核会将 I/O 准备好的描述符加入到一个链表中管理，进程调用 epoll_wait() 便可以得到事件完成的描述符。

  - 从上面的描述可以看出，epoll 只需要将描述符从进程缓冲区向内核缓冲区拷贝一次，并且进程不需要通过轮询来获得事件完成的描述符。

  - epoll 仅适用于 Linux OS。

  - epoll 比 select 和 poll 更加灵活而且没有描述符数量限制。

  - epoll 对多线程编程更有友好，一个线程调用了 epoll_wait() 另一个线程关闭了同一个描述符也不会产生像 select 和 poll 的不确定情况。

  - 描述符事件触发模式

    - LT（level trigger）

      当 epoll_wait() 检测到描述符事件到达时，将此事件通知进程，进程**可以不立即处理**该事件，下次调用 epoll_wait() 会再次通知进程。是默认的一种模式，并且**同时支持 Blocking 和 No-Blocking**。

    - ET（edge trigger）

      通知之后进程**必须立即处理**事件，下次再调用 epoll_wait() 时不会再得到事件到达的通知。很大程度上减少了 epoll 事件被重复触发的次数，因此**效率要比 LT 模式高**。**只支持 No-Blocking**，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。

- **应用场景**

  - select

    - select 的 timeout 参数精度为微秒，而 poll 和 epoll 为毫秒，因此 select 更加适用于实时性要求比较高的场景，比如核反应堆的控制。
    - select 可移植性更好，几乎被所有主流平台所支持。

  - poll

    poll 没有最大描述符数量的限制，如果平台支持并且对实时性要求不高，应该使用 poll 而不是 select。

  - epoll

    - 只需运行在Linux平台上，有大量描述符需要同时轮询，并且这些连接最好是长连接。
    - 需要同时监控小于 1000 个描述符，就没有必要使用 epoll，因为这个应用场景下并不能体现 epoll 的优势。
    - 需要监控的描述符状态变化多，而且都是非常短暂的，也没有必要使用 epoll。因为 epoll 中的所有描述符都存储在内核中，造成每次需要对描述符的状态改变都需要通过 epoll_ctl() 进行系统调用，频繁系统调用降低效率。并且 epoll 的描述符存储在内核，不容易调试。

#### 7.8.2.4 信号驱动I/O

- 应用进程使用 sigaction 系统调用，内核立即返回，应用进程可以继续执行，也就是说等待数据阶段应用进程是非阻塞的。内核在数据到达时向应用进程发送 SIGIO 信号，应用进程收到之后在信号处理程序中调用 recvfrom 将数据从内核复制到应用进程中。
- 相比于非阻塞式 I/O 的轮询方式，信号驱动 I/O 的 CPU 利用率更高。

![信号驱动I/O](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/1492929553651_7.png)

#### 7.8.2.5 异步I/O

- 应用进程执行 aio_read 系统调用会立即返回，应用进程可以继续执行，不会被阻塞，内核会在所有操作完成之后向应用进程发送信号。
- 异步 I/O 与信号驱动 I/O 的区别在于，异步 I/O 的信号是通知应用进程 I/O 完成，而信号驱动 I/O 的信号是通知应用进程可以开始 I/O。

![异步I/O](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/1492930243286_8.png)

#### 7.8.2.6 五大I/O模型比较

- **同步 I/O**：将数据从内核缓冲区复制到应用进程缓冲区的阶段**（第二阶段），应用进程会阻塞**。
- **异步 I/O**：**第二阶段应用进程不会阻塞**。

|          | 阻塞式I/O | 非阻塞式I/O | I/O复用 | 信号驱动I/O | 异步I/O |
| -------- | --------- | ----------- | ------- | ----------- | ------- |
| 第一阶段 | 阻塞      | 不阻塞      | 阻塞    | 不阻塞      | 不阻塞  |
| 第二阶段 | 阻塞      | 阻塞        | 阻塞    | 阻塞        | 不阻塞  |
| 同步与否 | 同步      | 同步        | 同步    | 同步        | 异步    |

### 7.9 远程过程调用RPC

#### 7.9.1 进程间通信IPC

- **IPC（Inter-process Communication）**：不同的程序运行起来，对应不同的进程。**为完成功能，不同进程之间可能需要传播或交换信息，这就是IPC**。这种相互通信又可以称为相互调用。
- IPC的方法主要包括：**管道，有名管道，消息队列，信号，共用内存，套接字**。[详细介绍](https://www.jianshu.com/p/c1015f5ffa74)
- 对**Inter-process通过所在空间**进行分类：
  - **LPC**（Local Procedure Call）：在同一个操作系统中运行的IPC
  - **RPC**（Remote Procedure Call）：不在同一个操作系统中的IPC

#### 7.9.2 本地过程调用LPC

​		本地过程调用（LPC，Local Procedure Call，通常也被称为轻量过程调用或者本地进程间通信） 是一种由Windows NT内核提供的内部进程间通信方式。因为是本地，所以前面的IPC方法均可使用，包括套接字Socket（可以自己和自己建立Socket连接）。

#### 7.9.3 RPC

​		**RPC是一种通过网络从远程计算机程序上请求服务，而不需要了解底层网络技术的思想**。

​		因为要通过网络，所以采用IPC方法中的**套接字**方式进行通信，同时可以引入**消息队列**机制，来提高通信性能。

- 常见RPC技术和框架
  - 应用级的服务框架：阿里的 Dubbo/Dubbox、Google gRPC、Spring Boot/Spring Cloud。
  - 远程通信协议：RMI、Socket、SOAP(HTTP XML)、REST(HTTP JSON)。
  - 通信框架：MINA 和 Netty。

- **架构**

  ![RCP架构图](https://raw.githubusercontent.com/Moxiansheng/practiceCoding/master/img/20210117112051.jpeg)

- **核心功能**

  - ***序列化***
  - ***协议编码***
  - ***网络传输***

- **核心组成**

  - **客户端(Client)**：服务调用方
  - **客户端存根(Client Stub)**：存放服务端地址信息，将客户端的请求参数数据信息打包成网络消息，再通过网络传输发送给服务端
  - **服务端存根(Server Stub)**：接收客户端发送过来的请求消息并进行解包，然后再调用本地服务进行处理
  - **服务端(Server)**：服务的真正提供者
  - **Network Service**：底层传输，可以是 TCP 或 HTTP

- **调用过程**

  - 服务消费者(Client 客户端)通过本地调用的方式调用服务。
  - 客户端存根(Client Stub)接收到调用请求后负责将方法、入参等信息序列化(组装)成能够进行网络传输的消息体。
  - 客户端存根(Client Stub)找到远程的服务地址，并且将消息通过网络发送给服务端。
  - 服务端存根(Server Stub)收到消息后进行解码(反序列化操作)。
  - 服务端存根(Server Stub)根据解码结果调用本地的服务进行相关处理
  - 服务端(Server)本地服务业务处理。
  - 处理结果返回给服务端存根(Server Stub)。
  - 服务端存根(Server Stub)序列化结果。
  - 服务端存根(Server Stub)将结果通过网络发送至消费方。
  - 客户端存根(Client Stub)接收到消息，并进行解码(反序列化)。
  - 服务消费方得到最终结果。

- **三大技术点**

  - **Call ID映射**。
    - 在本地调用中，函数体是直接通过函数指针来指定的，我们调用Multiply，编译器就自动帮我们调用它相应的函数指针。但是在远程调用中，函数指针是不行的，因为两个进程的地址空间是完全不一样的。
    - 所以，**在RPC中，所有的函数都必须有自己的一个ID。这个ID在所有进程中都是唯一确定的。客户端在做远程过程调用时，必须附上这个ID。然后我们还需要在客户端和服务端分别维护一个 {函数 <--> Call ID} 的对应表**。
    - **两者的表不一定需要完全相同，但相同的函数对应的Call ID必须相同**。当客户端需要进行远程调用时，它就查一下这个表，找出相应的Call ID，然后把它传给服务端，服务端也通过查表，来确定客户端需要调用的函数，然后执行相应函数的代码。
    - **客户端的表通过查询服务端对外暴露的服务注册中心获取**。服务端开发完功能后，需要将功能注册到服务注册中心。Dubbo 的服务注册中心是可以配置的，官方推荐使用 Zookeeper。
  - **序列化和反序列化**。
    - 想把参数传给要调用的函数，在本地调用中，我们只需要把参数压到栈里，然后让函数自己去栈里读就行。
    - 但是在远程过程调用时，客户端跟服务端是不同的进程，不能通过内存来传递参数。甚至有时候客户端和服务端使用的都不是同一种语言。
    - 此时**客户端把参数先转成一个字节流，传给服务端后，再把字节流转成自己能读取的格式。这个过程叫序列化和反序列化。同理，从服务端返回的值也需要序列化反序列化的过程**。
    - 因为只有二进制的数据才能在网络中传输，所以更准确的定义是：
      - 将传输数据转换成二进制流的过程叫做序列化
      - 将二进制流转换成原始数据的过程叫做反序列化
  - **网络传输**。
    - 远程调用往往用在网络上，客户端和服务端是通过网络连接的。所有的数据都需要通过网络传输，因此就需要有一个**网络传输层**。
    - **网络传输层需要把Call ID和序列化后的参数字节流传给服务端，然后再把序列化后的调用结果传回客户端。**只要能完成这两者的，都可以作为传输层使用。
    - **可使用的协议是不限的，能完成传输就行。尽管大部分RPC框架都使用TCP协议，但其实UDP也可以，而gRPC干脆就用了HTTP2。Java的Netty也属于这层的东西。**

- **消息队列**

  引入MQ（Message Queue）可以**提高消息传递过程中的安全性和稳定性**。

  使用RabbitMQ的好处：

  - **同步变异步**：可以使用线程池将同步变成异步，但是缺点是要自己实现线程池，并且强耦合。使用消息队列可以轻松将同步请求变成异步请求。

  - **低内聚高耦合**：解耦，减少强依赖。

  - **流量削峰**：通过消息队列设置请求最大值，超过阀值的抛弃或者转到错误界面。

  - **网络通信性能提高**：TCP 的创建和销毁开销大，创建 3 次握手，销毁 4 次分手，高峰时成千上万条的链接会造成资源的巨大浪费，而且操作系统每秒处理 TCP 的数量也是有数量限制的，必定造成性能瓶颈。

    RabbitMQ 采用信道通信，不采用 TCP 直接通信。一条线程一条信道，多条线程多条信道，公用一个 TCP 连接。

### 7.10 HTTP

#### 7.10.1 请求和响应报文

- 请求报文结构
  - 第一行是包含了请求方法、URL、协议版本；
  - 接下来的多行都是请求首部 Header，每个首部都有一个首部名称，以及对应的值。
  - 一个空行用来分隔首部和内容主体 Body
  - 最后是请求的内容主体

  ```http
  GET http://www.example.com/ HTTP/1.1
  Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9
  Accept-Encoding: gzip, deflate
  Accept-Language: zh-CN,zh;q=0.9,en;q=0.8
  Cache-Control: max-age=0
  Host: www.example.com
  If-Modified-Since: Thu, 17 Oct 2019 07:18:26 GMT
  If-None-Match: "3147526947+gzip"
  Proxy-Connection: keep-alive
  Upgrade-Insecure-Requests: 1
  User-Agent: Mozilla/5.0 xxx
  
  param1=1&param2=2
  ```

- 响应报文结构

  - 第一行包含协议版本、状态码以及描述，最常见的是 200 OK 表示请求成功了
  - 接下来多行也是首部内容
  - 一个空行分隔首部和内容主体
  - 最后是响应的内容主体

  ```http
  HTTP/1.1 200 OK
  Age: 529651
  Cache-Control: max-age=604800
  Connection: keep-alive
  Content-Encoding: gzip
  Content-Length: 648
  Content-Type: text/html; charset=UTF-8
  Date: Mon, 02 Nov 2020 17:53:39 GMT
  Etag: "3147526947+ident+gzip"
  Expires: Mon, 09 Nov 2020 17:53:39 GMT
  Keep-Alive: timeout=4
  Last-Modified: Thu, 17 Oct 2019 07:18:26 GMT
  Proxy-Connection: keep-alive
  Server: ECS (sjc/16DF)
  Vary: Accept-Encoding
  X-Cache: HIT
  
  <!doctype html>
  <html>
  <head>
      <title>Example Domain</title>
  	// 省略... 
  </body>
  </html>
  ```

#### 7.10.2 HTTP方法

- GET：获取资源
- HEAD：获取报文首段
- POST：传输实体主体
- PUT：上传文件
- PATCH：对资源进行部分修改
- DELETE：删除文件
- OPTIONS：查询支持的方法
- CONNECT：要求在与代理服务器通信时建立隧道
- TRACE：追踪路径

#### 7.10.3 HTTP状态码

| 状态码 |               类别               |            含义            |
| :----: | :------------------------------: | :------------------------: |
|  1XX   |  Informational（信息性状态码）   |     接收的请求正在处理     |
|  2XX   |      Success（成功状态码）       |      请求正常处理完毕      |
|  3XX   |   Redirection（重定向状态码）    | 需要进行附加操作以完成请求 |
|  4XX   | Client Error（客户端错误状态码） |     服务器无法处理请求     |
|  5XX   | Server Error（服务器错误状态码） |     服务器处理请求出错     |

#### 1XX 信息

- **100 Continue** ：表明到目前为止都很正常，客户端可以继续发送请求或者忽略这个响应。

#### 2XX 成功

- **200 OK**
- **204 No Content** ：请求已经成功处理，但是返回的响应报文不包含实体的主体部分。一般在只需要从客户端往服务器发送信息，而不需要返回数据时使用。
- **206 Partial Content** ：表示客户端进行了范围请求，响应报文包含由 Content-Range 指定范围的实体内容。

#### 3XX 重定向

- **301 Moved Permanently** ：永久性重定向
- **302 Found** ：临时性重定向
- **303 See Other** ：和 302 有着相同的功能，但是 303 明确要求客户端应该采用 GET 方法获取资源。
- 注：虽然 HTTP 协议规定 301、302 状态下重定向时不允许把 POST 方法改成 GET 方法，但是大多数浏览器都会在 301、302 和 303 状态下的重定向把 POST 方法改成 GET 方法。
- **304 Not Modified** ：如果请求报文首部包含一些条件，例如：If-Match，If-Modified-Since，If-None-Match，If-Range，If-Unmodified-Since，如果不满足条件，则服务器会返回 304 状态码。
- **307 Temporary Redirect** ：临时重定向，与 302 的含义类似，但是 307 要求浏览器不会把重定向请求的 POST 方法改成 GET 方法。

#### 4XX 客户端错误

- **400 Bad Request** ：请求报文中存在语法错误。
- **401 Unauthorized** ：该状态码表示发送的请求需要有认证信息（BASIC 认证、DIGEST 认证）。如果之前已进行过一次请求，则表示用户认证失败。
- **403 Forbidden** ：请求被拒绝。
- **404 Not Found**

#### 5XX 服务器错误

- **500 Internal Server Error** ：服务器正在执行请求时发生错误。
- **503 Service Unavailable** ：服务器暂时处于超负载或正进行停机维护，现在无法处理请求。

#### 7.10.4 GET和POST比较

- **作用**

  - GET 用于获取资源，

  - POST 用于传输实体主体。

- **参数**

  - GET 的参数是以查询字符串出现在 URL 中，因为 URL 只支持 ASCII 码，因此 GET 的参数中如果存在中文等字符就需要先进行编码。
  - POST 的参数存储在实体主体中。支持标准字符集。POST并没有因为数存储在实体主体中就更安全，因为照样可以通过一些抓包工具（Fiddler）查看。

- **安全**

  安全的 HTTP 方法不会改变服务器状态，也就是说它只是可读的。

  安全的方法：GET，HEAD，OPTIONS

  不安全的方法：POST，PUT，DELETE

- **幂等性**

  幂等的 HTTP 方法，同样的请求被执行一次与连续执行多次的效果相同，服务器状态也相同。

  幂等的方法：GET，HEAD，PUT，DELETE

  非幂等方法：POST

- **可缓存**

  如果要对响应进行缓存，需要满足以下条件：

  - 请求报文的 HTTP 方法本身是**可缓存的，包括 GET 和 HEAD，但是 PUT 和 DELETE 不可缓存，POST 在多数情况下不可缓存的**。
  - **响应报文的状态码是可缓存的**，包括：200, 203, 204, 206, 300, 301, 404, 405, 410, 414, and 501。
  - **响应报文的 Cache-Control 首部字段没有指定不进行缓存**。

- **XMLHttpRequest**

  [XMLHttpRequest](https://www.w3school.com.cn/xmldom/dom_http.asp) 是一个 API，它为客户端提供了在客户端和服务器之间传输数据的功能。它提供了一个通过 URL 来获取数据的简单方式，并且不会使整个页面刷新。这使得网页只更新一部分页面而不会打扰到用户。XMLHttpRequest 在 AJAX 中被大量使用。

  - 在使用 XMLHttpRequest 的 POST 方法时，浏览器会先发送 Header 再发送 Data。但并不是所有浏览器会这么做，例如火狐就不会。
  - 而 GET 方法 Header 和 Data 会一起发送。

#### 7.10.5 短连接与长连接

- **短连接**：在HTTP/1.1之前默认使用短连接。一次HTTP操作建立一次连接。操作完毕连接完毕。
- **长连接**：在HTTP/1.1开始长连接。响应头加入Connection:keep-alive。
- **HTTP协议的长连接和短连接，实质上是TCP协议的长连接和短连接。**

#### 7.10.6 流水线

默认情况下，HTTP 请求是按顺序发出的，下一个请求只有在当前请求收到响应之后才会被发出。由于受到网络延迟和带宽的限制，在下一个请求被发送到服务器之前，可能需要等待很长时间。

流水线是在同一条长连接上连续发出请求，而不用等待响应返回，这样可以减少延迟。

#### 7.10.7 Cookie

HTTP 协议是无状态的，主要是为了让 HTTP 协议尽可能简单，使得它能够处理大量事务。

Cookie 是**服务器发送到用户浏览器**并**保存在本地的一小块数据**，它会在浏览器之后向同一服务器再次发起请求时被携带上，用于告知服务端两个请求是否来自同一浏览器。由于之后每次请求都会需要携带 Cookie 数据，因此会带来额外的性能开销（尤其是在移动环境下）。

- 用途
  - 会话状态管理（如用户登录状态、购物车、游戏分数或其它需要记录的信息）
  - 个性化设置（如用户自定义设置、主题等）
  - 浏览器行为跟踪（如跟踪分析用户行为等）
- 创建过程
  - 服务器发送的响应报文包含 Set-Cookie 首部字段，客户端得到响应报文后把 Cookie 内容保存到浏览器中。
  - 客户端之后对同一个服务器发送请求时，会从浏览器中取出 Cookie 信息并通过 Cookie 请求首部字段发送给服务器。
- 分类
  - 会话期 Cookie：浏览器关闭之后它会被自动删除，也就是说它仅在会话期内有效。
  - 持久性 Cookie：指定过期时间（Expires）或有效期（max-age）之后就成为了持久性的 Cookie。

#### 7.10.8 Session

除了可以将用户信息通过 Cookie 存储在用户浏览器中，也可以利用 Session 存储在服务器端，存储在服务器端的信息更加安全。

- 使用过程
  - 用户进行登录时，用户提交包含用户名和密码的表单，放入 HTTP 请求报文中；
  - 服务器验证该用户名和密码，如果正确则把用户信息存储到 Redis 中，它在 Redis 中的 Key 称为 Session ID；
  - 服务器返回的响应报文的 Set-Cookie 首部字段包含了这个 Session ID，客户端收到响应报文之后将该 Cookie 值存入浏览器中；
  - 客户端之后对同一个服务器进行请求时会包含该 Cookie 值，服务器收到之后提取出 Session ID，从 Redis 中取出用户信息，继续之前的业务操作。

#### 7.10.9 浏览器禁用Cookie

此时无法使用 Cookie 来保存用户信息，只能使用 Session。除此之外，不能再将 Session ID 存放到 Cookie 中，而是使用 URL 重写技术，将 Session ID 作为 URL 的参数进行传递。

#### 7.10.10 Cookie与Session比较

- Cookie 只能存储 ASCII 码字符串，而 Session 则可以存储任何类型的数据，因此在考虑数据复杂性时首选 Session；
- Cookie 存储在浏览器中，容易被恶意查看。如果非要将一些隐私数据存在 Cookie 中，可以将 Cookie 值进行加密，然后在服务器进行解密；
- 对于大型网站，如果用户所有的信息都存储在 Session 中，那么开销是非常大的，因此不建议将所有的用户信息都存储到 Session 中。

#### 7.10.11 虚拟主机

HTTP/1.1 使用虚拟主机技术，使得一台服务器拥有多个域名，并且在逻辑上可以看成多个服务器。

#### 7.10.12 通信数据转发

- **代理**

  代理服务器接受客户端的请求，并且转发给其它服务器。

  主要目的：

  - 缓存
  - 负载均衡
  - 网络访问控制
  - 访问日志记录

  分类：

  - 正向代理：用户察觉得到正向代理的存在
  - 反向代理：反向代理一般位于内部网络中，用户察觉不到

- **网关**

  与代理服务器不同的是，网关服务器会将 HTTP 转化为其它协议进行通信，从而请求其它非 HTTP 服务器的服务。

- **隧道**

  使用 SSL 等加密手段，在客户端和服务器之间建立一条安全的通信线路。

#### 7.10.12 HTTPS

- HTTP的安全问题

  - 使用明文进行通信，内容可能会被窃听；
  - 不验证通信方的身份，通信方的身份有可能遭遇伪装；
  - 无法证明报文的完整性，报文有可能遭篡改。

  HTTPS是让HTTP先和SSL（Secure Sockets Layer）通信，再由SSL和TCP通信。

  HTTPS通过使用隧道通信，具有了**加密(防窃听)**、**认证(防伪装)**和**完整性保护(防篡改)**。

- **加密**
  - **对称密钥加密**：加密和解密使用同一密钥
    - 优点：运算速度快；
    - 缺点：无法安全地将密钥传输给通信方。
  - **非对称密钥加密**：加密和解密使用不同的密钥，分公私钥
    - 优点：可以更安全地将公开密钥传输给通信发送方；
    - 缺点：运算速度慢。
  - **HTTPS采用的加密方式**
    - 使用非对称密钥加密方式，传输对称密钥加密方式所需要的 Secret Key，从而保证安全性;
    - 获取到 Secret Key 后，再使用对称密钥加密方式进行通信，从而保证效率。（下图中的 Session Key 就是 Secret Key）

- **认证**
  - 通过使用 **证书** 来对通信方进行认证。
  - 数字证书认证机构（CA，Certificate Authority）是客户端与服务器都信赖的第三方机构。
  - 服务器的运营人员向 CA 提出公开密钥的申请，CA 在判明提出申请者的身份之后，会对已申请的公开密钥做数字签名，然后分配这个已签名的公开密钥，并将该公开密钥放入公开密钥证书后绑定在一起。
  - 进行 HTTPS 通信时，服务器会把证书发送给客户端。客户端取得其中的公开密钥之后，先使用数字签名进行验证，如果验证通过，就可以开始通信了。
  
- **完整性保护**
  - HTTP 也提供了 MD5 报文摘要功能，但不是安全的。例如报文内容被篡改之后，同时重新计算 MD5 的值，通信接收方是无法意识到发生了篡改。
  - HTTPS 的报文摘要功能之所以安全，是因为它结合了加密和认证这两个操作。

- **缺点**
  - 因为需要进行加密解密等过程，因此速度会更慢；
  - 需要支付证书授权的高额费用。
  
- **SSL(Secure Sockets Layer) & TLS(Transport Layer Security)**

  - 什么是SSL&TLS

    - SSL及其继任者TSL是为网络通信提供安全及数据完整性的一种安全协议。TLS与SSL在**传输层**对网络连接进行加密。

    - SSL&TLS都可以分为两部分协议
      - 记录协议（SSL/TLS Record Protocol）：它**建立在可靠的传输协议（如TCP）之上**，为高层协议提供数据**封装**、**压缩**、**加密**等基本功能的支持。
      - 握手协议（SSL/TLS Handshake Protocol）：它建立在记录协议之上，用于在实际的数据传输开始前，通讯双方进行**身份认证、协商加密算法、交换加密密钥**等。

  - SSL&TLS提供的服务

    - 认证用户和服务器，确保数据发送到正确的客户机和服务器；
    - 加密数据以防止数据中途被窃取；
    - 维护数据的完整性，确保数据在传输过程中不被改变

  - **SSL&TLS工作原理**

    ![SSL&TLS工作原理](https://raw.githubusercontent.com/Moxiansheng/practiceCoding/master/img/20210117094554.png)

  - **RSA认证隐患**

    - **中间人攻击**

      - 客户端C和服务器S进行通信，中间节点M截获了二者的通信;
      - 节点M自己计算产生一对公钥pub_M和私钥pri_M;
      - C向S请求公钥时，M把自己的公钥pub_M发给了C;
      - C使用公钥 pub_M加密的数据能够被M解密，因为M掌握对应的私钥pri_M，而 C无法根据公钥信息判断服务器的身份，从而 C和 M之间建立了"可信"加密连接;
      - 中间节点 M和服务器S之间再建立合法的连接，因此 C和 S之间通信被M完全掌握，M可以进行信息的窃听、篡改等操作。

    - **信息抵赖**

      服务器可以对自己的发出的信息进行否认，不承认相关信息是自己发出。

  - **CA与证书**

    - 解决上述身份验证问题的关键是确保获取的公钥途径是合法的，能够验证服务器的身份信息，为此需要引入权威的**第三方机构CA**。

    - CA 负责核实公钥的拥有者的信息，并颁发认证"证书"，同时能够为使用者提供证书验证服务，即PKI体系(PKI基础知识)。

    - 基本原理为，CA负责审核信息，然后对关键信息利用私钥进行"签名"，公开对应的公钥，客户端可以利用公钥验证签名。CA也可以吊销已经签发的证书，基本的方式包括两类 CRL 文件和OCSP。

    - 证书吊销的两种机制

      - **CRL**

        Certificate Revocation List, 证书吊销列表，一个单独的文件。该文件包含了 CA 已经吊销的证书序列号(唯一)与吊销日期，同时该文件包含生效日期并通知下次更新该文件的时间，当然该文件必然包含 CA 私钥的签名以验证文件的合法性。

      - **OCSP**

        Online Certificate Status Protocol, 证书状态在线查询协议，一个实时查询证书是否吊销的方式。请求者发送证书的信息并请求查询，服务器返回正常、吊销或未知中的任何一个状态。

  - **SSL&TLS握手流程**

    ![握手流程](https://raw.githubusercontent.com/Moxiansheng/practiceCoding/master/img/20210117095348.png)

    1. **client_hello**

       客户端发起请求，以明文传输请求信息，包含版本信息，加密套件候选列表，压缩算法候选列表，随机数，扩展字段等信息，相关信息如下：

       - 支持的最高TSL协议版本version，从低到高依次 SSLv2 SSLv3 TLSv1 TLSv1.1 TLSv1.2，当前基本不再使用低于 TLSv1 的版本;
       - 客户端支持的加密套件 cipher suites 列表， 每个加密套件对应前面 TLS 原理中的四个功能的组合：认证算法 Au (身份验证)、密钥交换算法 KeyExchange(密钥协商)、对称加密算法 Enc (信息加密)和信息摘要 Mac(完整性校验);
       - 支持的压缩算法 compression methods 列表，用于后续的信息压缩传输;
       - 随机数 random_C，用于后续的密钥的生成;
       - 扩展字段 extensions，支持协议与算法的相关参数以及其它辅助信息等，常见的 SNI 就属于扩展字段，后续单独讨论该字段作用。

    2. **server_hello+server_certificate+sever_hello_done**

       - server_hello, 服务端返回协商的信息结果，包括选择使用的协议版本 version，选择的加密套件 cipher suite，选择的压缩算法 compression method、随机数 random_S 等，其中随机数用于后续的密钥协商;
       - server_certificates, 服务器端配置对应的证书链，用于身份验证与密钥交换;
       - server_hello_done，通知客户端 server_hello 信息发送结束;

    3. **证书校验**

       客户端验证证书的合法性，如果验证通过才会进行后续通信，否则根据错误情况不同做出提示和操作，合法性验证包括如下：

       - [证书链]的可信性 trusted certificate path，方法如前文所述;
       - 证书是否吊销 revocation，有两类方式离线 CRL 与**在线** **OCSP**，不同的客户端行为会不同;
       - 有效期 expiry date，证书是否在有效时间范围;
       - 域名 domain，核查证书域名是否与当前的访问域名匹配，匹配规则后续分析;

    4. **client_key_exchange+change_cipher_spec+encrypted_handshake_message**

       - client_key_exchange，合法性验证通过之后，客户端计算产生随机数字 Pre-master，并用证书公钥加密，发送给服务器;
       - 此时客户端已经获取全部的计算协商密钥需要的信息：两个明文随机数 random_C 和 random_S 与自己计算产生的 Pre-master，计算得到协商密钥; enc_key=Fuc(random_C, random_S, Pre-Master)
       - change_cipher_spec，客户端通知服务器后续的通信都采用协商的通信密钥和加密算法进行加密通信;
       - encrypted_handshake_message，结合之前所有通信参数的 hash 值与其它相关信息生成一段数据，采用协商密钥 session secret 与算法进行加密，然后发送给服务器用于数据与握手验证;

    5. **change_cipher_spec+encrypted_handshake_message**

       - 服务器用私钥解密加密的 Pre-master 数据，基于之前交换的两个明文随机数 random_C 和 random_S，计算得到协商密钥:enc_key=Fuc(random_C, random_S, Pre-Master);
       - 计算之前所有接收信息的 hash 值，然后解密客户端发送的 encrypted_handshake_message，验证数据和密钥正确性;
       - change_cipher_spec, 验证通过之后，服务器同样发送 change_cipher_spec 以告知客户端后续的通信都采用协商的密钥与算法进行加密通信;
       - encrypted_handshake_message, 服务器也结合所有当前的通信参数信息生成一段数据并采用协商密钥session secret 与算法加密并发送到客户端;

    6. **握手结束**

       客户端计算所有接收信息的 hash 值，并采用协商密钥解密encrypted_handshake_message，验证服务器发送的数据和密钥，验证通过则握手完成;

    7. **加密通信**

       开始使用协商密钥与算法进行加密通信。

       > 1. 服务器也可以要求验证客户端，即双向认证，可以在过程2要发送 client_certificate_request 信息，客户端在过程4中先发送 client_certificate与certificate_verify_message 信息，证书的验证方式基本相同，certificate_verify_message 是采用client的私钥加密的一段基于已经协商的通信信息得到数据，服务器可以采用对应的公钥解密并验证;
       > 2. 根据使用的密钥交换算法的不同，如 ECC 等，协商细节略有不同，总体相似;
       > 3. sever key exchange 的作用是 server certificate 没有携带足够的信息时，发送给客户端以计算 pre-master，如基于 DH 的证书，公钥不被证书中包含，需要单独发送;
       > 4. change cipher spec 实际可用于通知对端改版当前使用的加密通信方式，当前没有深入解析;
       > 5. alter message 用于指明在握手或通信过程中的状态改变或错误信息，一般告警信息触发条件是连接关闭，收到不合法的信息，信息解密失败，用户取消操作等，收到告警信息之后，通信会被断开或者由接收方决定是否断开连接。

  - **会话缓存的握手流程**

    为了加快建立握手的速度，减少协议带来的性能降低和资源消耗，TLS 协议有两类会话缓存机制：会话标识 session ID 与会话记录 session ticket。

    - **session ID** 由服务器端支持，协议中的标准字段，因此基本所有服务器都支持，服务器端保存会话ID以及协商的通信信息，Nginx 中1M 内存约可以保存4000个 session ID 机器相关信息，占用服务器资源较多;

    - **session ticket** 需要服务器和客户端都支持，属于一个扩展字段。将协商的通信信息加密之后发送给客户端保存，密钥只有服务器知道，占用服务器资源很少。

    **二者对比，主要是保存协商信息的位置与方式不同**，类似与 http 中的 session 与 cookie。

    二者都存在的情况下，(nginx 实现)优先使用 session_ticket。

    ![会话缓存的握手流程](https://img2018.cnblogs.com/blog/1071910/201810/1071910-20181028220836095-2009018125.png)

    **注意：**虽然握手过程有1.5个来回，但是最后客户端向服务器发送的第一条应用数据不需要等待服务器返回的信息，因此握手延时是1*RTT。

    **TLS会话恢复（TLS Session Resumption）**

    - 这项技术是通过**预共享密钥（PSK）**实现的。依赖于在初始握手期间传递给客户端**设备的标识符**，并且因为这个**标识符（会话ID、会话记录单、PSK身份）在浏览器的TLS缓存中持续存在**，所以可以像跟踪任何其他数字标识符一样对其进行跟踪。
    - 为了降低通过TLS会话恢复标识符进行跟踪的风险，建议将TLS 1.3中指定的7天会话恢复上限时间减少至10分钟，以确保浏览器制造商解决第三方跟踪。

  - **重建连接**

    重建连接 renegotiation 即放弃正在使用的 TLS 连接，从新进行身份认证和密钥协商的过程，特点是**不需要断开当前的数据传输就可以重新身份认证、更新密钥或算法**，因此服务器端存储和缓存的信息都可以保持。

    - **服务器重建连接**

      ![服务器重建连接](https://raw.githubusercontent.com/Moxiansheng/practiceCoding/master/img/20210117101630.png)

      服务器端重建连接一般情况是**客户端访问受保护的数据时发生**。基本过程如下：

      1. 客户端和服务器之间建立了有效 TLS 连接并通信;
      2. 客户端访问受保护的信息;
      3. 服务器端返回 hello_request 信息;
      4. 客户端收到 hello_request 信息之后发送 client_hello 信息，开始重新建立连接。

    - **客户端重建连接**

      ![客户端重建连接](https://raw.githubusercontent.com/Moxiansheng/practiceCoding/master/img/20210117101630.png)

      客户端重建连接一般是**为了更新通信密钥**。

      1. 客户端和服务器之间建立了有效 TLS 连接并通信;
      2. 客户端需要更新密钥，主动发出 client_hello 信息;
      3. 服务器端收到 client_hello 信息之后无法立即识别出该信息非应用数据，因此会提交给下一步处理，处理完之后会返回通知该信息为要求重建连接;
      4. 在确定重建连接之前，服务器不会立即停止向客户端发送数据，可能恰好同时或有缓存数据需要发送给客户端，但是客户端不会再发送任何信息给服务器;
      5. 服务器识别出重建连接请求之后，发送 server_hello 信息至客户端;
      6. 客户端也同样无法立即判断出该信息非应用数据，同样提交给下一步处理，处理之后会返回通知该信息为要求重建连接;
      7. 客户端和服务器开始新的重建连接的过程。

#### 7.10.13 HTTP与HTTPS的区别

- HTTPS是加密传输协议，HTTP是明文传输协议;
- HTTPS需要用到SSL/TLS证书，而HTTP不用;
- HTTPS比HTTP更加安全，对搜索引擎更友好，利于SEO;
- HTTPS标准端口443，HTTP标准端口80;
- HTTPS基于传输层，HTTP基于应用层;
- HTTPS在浏览器显示绿色安全锁，HTTP没有显示;

#### 7.10.13 HTTP/1.1 新特性

- 默认是长连接
- 支持流水线（但返回时需按顺序且全部返回，并未真的实现）
- 支持同时打开多个 TCP 连接
- 支持虚拟主机
- 新增状态码 100
- 支持分块传输编码
- 新增缓存处理指令 max-age

#### 7.10.14 HTTP/2.0

- **HTTP/1.x缺陷**

  HTTP/1.x 实现简单是以牺牲性能为代价的

  - 客户端需要使用多个连接才能实现并发和缩短延迟；
  - 不会压缩请求和响应首部，从而导致不必要的网络流量；
  - 不支持有效的资源优先级，致使底层 TCP 连接的利用率低下。

- **二进制分帧层**

  HTTP/2.0 将报文分成 HEADERS 帧和 DATA 帧，它们都是二进制格式的。

  基于二进制格式解析的HTTP2.0协议，实现了方便和健壮。

- **多路复用**

  在通信过程中，只会有**一个 TCP 连接**存在，它承载了**任意数量**的**双向数据流**（Stream）。

  - **一个数据流**（Stream）都有一个**唯一标识符**和**可选的优先级信息**，用于承载双向信息。
  - **消息（Message）**是与**逻辑请求或响应对应的完整的一系列帧**。
  - **帧（Frame）是最小的通信单位**，来自不同数据流的帧可以**交错发送**，然后再根据每个帧头的数据流标识符重新组装。

  相较于HTTP/1.x中的长连接复用（流水线），真正的实现了同一连接上的多请求并行执行。

  且HTTP/2 通过让所有数据流共用**同一个连接**，可以更有效地使用 TCP 连接，让高带宽也能真正的服务于 HTTP 的性能提升

- **头部压缩**

  - HTTP/1.1 的首部带有大量信息，而且每次都要重复发送。
  - HTTP/2.0 要求客户端和服务器同时维护和更新一个包含之前见过的首部字段表，从而避免了重复传输。
  - 不仅如此，HTTP/2.0 也使用 Huffman 编码对首部字段进行压缩。
  - 这样就大大减少了因重复头部传输产生的流量。

- **服务端推送**

  HTTP/2.0 在客户端请求一个资源时，会把相关的资源一起发送给客户端，客户端就不需要再次发起请求了。

  正因未发起请求，建立连接等操作，所以静态资源通过服务端推送的方式可极大地提升速度。
  
- **WebSocket**

  - WebSocket 协议本质上是一个基于 **TCP** 的协议，HTTP 完全不一样，只不过**为了兼容性**，WebSocket 的握手是以 HTTP 的形式发起的。

  - WebSocket使用 **ws** 或 **wss** 的统一资源标志符，ws类似于HTTP，wss类似于 HTTPS，其中 wss 表示在 TLS 之上的 Websocket。

  - WebSocket 使用和 **HTTP 相同的 TCP 端口**，可以绕过大多数防火墙的限制。默认情况下，WebSocket 协议使用 **80** 端口；运行在 TLS 之上时，默认使用 **443** 端口。

  - 经典WebSocket握手请求：

    **客户端请求**

    ```http
    GET / HTTP/1.1
    Upgrade: websocket
    Connection: Upgrade
    Host: example.com
    Origin: http://example.com
    Sec-WebSocket-Key: sN9cRrP/n9NdMgdcy2VJFQ==
    Sec-WebSocket-Protocol: chat, superchat
    Sec-WebSocket-Version: 13
    ```

    - **Connection 必须设置 Upgrade**，表示客户端希望连接升级。
    - **Upgrade 字段必须设置 Websocket**，表示希望升级到 Websocket 协议。
    - **Sec-WebSocket-Key** 是随机的字符串，服务器端会用这些数据来构造出一个 SHA-1 的信息摘要。以验证服务器是否真的支持WebSocket。如何构造，会在后面说明。
    - **Sec_WebSocket-Protocol** 是一个用户定义的字符串，用来区分同URL下，不同的服务所需要的协议。
    - **Sec-WebSocket-Version** 表示支持的 Websocket 版本。RFC6455 要求使用的版本是 13，之前草案的版本均应当弃用。
    - **Origin** 字段是可选的，通常用来表示在浏览器中发起此 Websocket 连接所在的页面，类似于 Referer。但是，与 Referer 不同的是，Origin 只包含了协议和主机名称。

    **服务器回应**

    ```http
    HTTP/1.1 101 Switching Protocols
    Upgrade: websocket
    Connection: Upgrade
    Sec-WebSocket-Accept: fFBooB7FAkLlXgRSz0BT3v4hq5s=
    Sec-WebSocket-Protocol: chat
    Sec-WebSocket-Location: ws://example.com/
    ```

    - **Sec-WebSocket-Accept** 这个是经过服务器处理加密后的Key，用以返回给客户端进行验证，若客户端用自己发送的Key也算出这个值，就算认证成功。

      **Sec-WebSocket-Accept = base64(hsa1(sec-websocket-key + 258EAFA5-E914-47DA-95CA-C5AB0DC85B11))**

      也就用客户端发来的“Sec-WebSocket-Key: sN9cRrP/n9NdMgdcy2VJFQ==”，与字符串形式的“258EAFA5-E914-47DA-95CA-C5AB0DC85B11”进行拼接，然后通过hsa1加密，再进行base64处理。

    - **Sec-WebSocket-Protocol** 则是表示最终使用的协议。

> ​		对于此标头字段，服务器必须采用该值（如标头字段中所示，例如base64编码的[RFC4648]版本减去任何开头和结尾的空格），并将其与全局唯一标识符（GUID，[RFC4122 ]）字符串形式的“ 258EAFA5-E914-47DA-95CA-C5AB0DC85B11”拼接，不了解WebSocket协议的网络端点不太可能使用它。然后，在服务器的握手中返回此串联的SHA-1哈希（160位）[FIPS.180-3]（已进行base64编码）（请参见[RFC4648]的第4节）。 
>
> [https://tools.ietf.org/html/rfc6455#section-5.5.2](https://tools.ietf.org/html/rfc6455#section-5.5.2)

------

![总览](D:\IDEA projects\practiceCoding\docs\network\2020102514243717.png)