# 操作系统

## 1. 操作系统基础

### 1.1 什么是操作系统

- **操作系统（Operating System，OS）是管理计算机硬件软件资源的程序，是计算机的基石。**

- **操作系统存在屏蔽了硬件层的复杂性。**

- **操作系统的内核（Kernel）是操作系统的核心部分，它负责系统的内存管理，硬件设备的管理，文件系统的管理以及应用程序的管理**。内核是连接应用程序和硬件的桥梁，决定着系统的性能和稳定性。

  ​							Applications <---> Kernel <---> CPU, Memory, Devices

### 1.2 内核 Kernel

1. **操作系统的内核（Kernel）是操作系统的核心部分，它负责系统的内存管理，硬件设备的管理，文件系统的管理以及应用程序的管理。**
2. **操作系统的内核是连接应用程序和硬件的桥梁，决定着操作系统的性能和稳定性。**
3. **直接对硬件操作是非常复杂的。所以内核通常提供一种硬件抽象的方法，来完成这些操作。有了这个，通过进程间通信机制及系统调用，应用进程可间接控制所需的硬件资源（特别是处理器及 IO 设备）。**

### 1.3 系统调用

- 系统调用是**操作系统提供给软件开发人员的唯一接口，开发人员可利用它使用系统功能**。**用户在程序中调用操作系统提供的子功能**称为系统调用。
- 系统态（管态）：**处理器运行系统程序的状态**。系统态运行的进程或程序几乎可以访问计算机全部资源。
- 用户态（算态）：**运行用户程序的状态**。用户态运行的进程或程序可以直接读取用户程序的数据，但不能读取系统的资源，必须通过系统调用向操作系统提出服务请求。
- 系统调用功能分类：
  - 设备管理。完成设备的请求或释放，以及设备启动等功能。
  - 文件管理。完成文件的读、写、创建及删除等功能。
  - 进程控制。完成进程的创建、撤销、阻塞及唤醒等功能。
  - 进程通信。完成进程之间的消息传递或信号传递等功能。
  - 内存管理。完成内存的分配、回收以及获取作业占用内存区大小及地址等功能。

### 1.4 中断分类

#### 1.4.1 外中断

由 CPU 执行指令以外的事件引起，如 I/O 完成中断，表示设备输入/输出处理已经完成，处理器能够发送下一个输入/输出请求。此外还有时钟中断、控制台中断等。

#### 1.4.2 异常

由 CPU 执行指令的内部事件引起，如非法操作码、地址越界、算术溢出等。

#### 1.4.3 陷入

在用户程序中使用系统调用。

## 2 进程

### 2.1 进程的表示

- **程序  数据  进程控制块PCB（唯一标识）**

- **是资源拥有单位**

### 2.2 进程几种状态

- **创建状态（new）**：进程正在被创建，尚未到就绪状态。
- **就绪状态（ready）**：进程已处于准备运行状态，即进程获得了除了处理器之外的一切所需资源，一旦得到处理器资源(处理器分配的时间片)即可运行。
- **运行状态（running）**：进程正在处理器上上运行(单核 CPU 下任意时刻只有一个进程处于运行状态)。
- **阻塞状态（waiting）**：又称为等待状态，进程正在等待某一事件而暂停运行如等待某资源为可用或等待 IO 操作完成。即使处理器空闲，该进程也不能运行。
- **结束状态（terminated）**：进程正在从系统中消失。可能是进程正常结束或其他原因中断退出运行。

![三种基本状态转换图](https://raw.githubusercontent.com/Moxiansheng/practiceCoding/master/img/20210116133604.png)

### 2.3 进程间通信

[《进程间通信 IPC (InterProcess Communication)》](https://www.jianshu.com/p/c1015f5ffa74) 

#### 2.3.1 管道/匿名管道(Pipes)

单向数据流；只能用于有亲缘的进程；匿名；缓冲区大小有限；传输数据无格式；FIFO；存于内存

#### 2.3.2 有名管道(Names Pipes)

FIFO；任意两个进程均可；存于磁盘或文件系统中；读写进程必须都在管道两侧

#### 2.3.3 信号(Signal)

Linux进程通信；无需知道被通知进程状态；若被通知进程阻塞，暂存于内核，后发

#### 2.3.4 消息队列(Message)

内核中的消息链表；消息队列标识符标识；存于内核；无需双方均在；FIFO||按类型读取

#### 2.3.5 共享内存(share memory)

- 使得多个进程可以可以直接读写同一块内存空间，是最快的可用IPC形式。

- 为在多个进程间交换信息，内核专门留出了一块内存区，可以由需要访问的进程将其映射到自己的私有地址空间。进程就可以直接读写此块内存而不需要进行数据的拷贝，大大提高效率。

- 由于多个进程共享一段内存，故需要依靠某种同步机制(如信号量)来达到进程间同步及互斥。

#### 2.3.6 信号量(Semaphores)

- 一个计数器
- 意图在于进程间同步
- 互斥：是为了某一资源同时只允许一个访问者对其访问，具有唯一性和排它性。但互斥无法限制访问者对资源的访问顺序，即访问是无序的。
- 同步：大部分情况下基于互斥，通过其它机制实现访问者对资源的有序访问。
- 互斥量值只能为0/1，信号量值可以为非负整数。
- 互斥量的加锁和解锁必须由同一线程分别对应使用，信号量可由一线程释放，另一线程得到。

#### 2.3.7 套接字(Sockets)

- 主要用于在客户端和服务器之间通过网络进行通信。
- 套接字是支持TCP/IP的网络通信的基本操作单元，可以看做是不同主机之间的进程进行双向通信的端点，简单的说就是通信的两方的一种约定，用套接字中的相关函数来完成通信过程。
- 三种套接字类型：流套接字（TCP），数据包套接字（UDP），原始套接字（其他协议）
- 原始套接字与标准套接字的区别：原始套接字可以读写内核没有处理的IP数据包，而流套接字只能读取TCP协议的数据，数据报套接字只能读取UDP协议的数据。因此，如果要访问其他协议发送数据必须使用原始套接字。

### 2.4 进程调度算法

#### 2.4.1 先到先服务调度算法（FCFS，First Come First Service）

从就绪队列中选择一个最先进入该队列的进程为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度。

#### 2.4.2 短作业优先调度算法（SJF，Shortest Job First）

从就绪队列中选出一个估计运行时间最短的进程为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度。**仅照顾了短进程而忽略了长进程** 。

#### 2.4.3 时间片轮转调度算法（RR，Round Robin）

每个进程被分配一个时间段，称作它的时间片，即该进程允许运行的时间。

#### 2.4.4 优先级调度算法

为每个流程分配优先级，首先执行具有最高优先级的进程，依此类推。具有相同优先级的进程以 FCFS 方式执行。可以根据内存要求，时间要求或任何其他资源要求来确定优先级。

#### 2.4.5 多级反馈队列调度算法

多级反馈队列调度算法既能使高优先级的作业得到响应又能使短作业（进程）迅速完成。因而它是目前**被公认的一种较好的进程调度算法**，UNIX 操作系统采取的便是这种调度算法。

- 机制
  - 设置多个就绪队列。在系统中设置多个就绪队列，并为每个队列赋予不同的优先级，从第一个开始逐个降低。不同队列进程中所赋予的执行时间不同，优先级越高，时间片越小。
  - 每个队列都采用FCFS（先来先服务）算法。轮到该进程执行时，若在该队列对应的时间片长度内完成，便撤离操作系统，否则调度程序将其转入下一队列的末尾等待调度。若最终转入到最后一个队列，此队列内采取RR方式调度
  - 按队列优先级调度。调度按照优先级最高队列中诸进程运行，仅当先前队列空闲时才调度后续队列进程执行。若优先级低队列执行中有优先级高队列进程执行，应立刻将此进程放入队列末尾，把处理机分配给新到高优先级进程。

### 2.5 进程与程序的区别

进程是程序的一次执行，该程序可以与其它程序并发执行。

- 进程是动态的，程序是静态的：程序是有序代码的集合；进程是程序的执行。通常进程不可在计算机之间迁移；而程序通常对应着文件、静态和可以复制。
- 进程是暂时的，程序是永久的：进程是一个状态变化的过程，程序可长久保存
- 进程与程序的对应关系：通过多次执行，一个程序可对应多个进程；通过调用关系，一个进程可包括多个程序。
- 进程与程序的组成不同：进程的组成包括程序、数据和进程控制块（即进程状态信息）

### 2.6 进程与线程的区别

- 线程定义：进程内一个**执行单元**或一个**可调度实体**。在具有多线程的操作系统中，处理机调度的基本单位是线程。一个进程可以有多个线程，而且**至少有一个可执行线程**。

- 线程是进程的一个组成部分。每个进程创建时通常只有一个线程，需要时可创建其他线程。
  - 进程的多线程都在进程的地址空间活动。
  - 资源是分给进程的，不是分给线程的。线程在执行中需要资源时，可从进程资源中划分。
  - 处理机调度的基本单位是线程，线程之间竞争处理机。**真正在CPU上运行的是线程**。
  - 线程在执行时，需要同步。

### 2.7 线程同步

线程同步是两或多个共享关键资源的线程的并发执行。应同步线程以避免关键资源使用冲突。

#### 2.7.1 **临界区**

对临界资源进行访问的那段代码称为临界区。

为了互斥访问临界资源，每个进程在进入临界区之前，需要先进行检查。

#### 2.7.2 同步与互斥

- 同步：多个进程因为合作产生的直接制约关系，使得进程有一定的先后执行关系。
- 互斥：多个进程在同一时刻只有一个进程能进入临界区。

#### 2.7.3 三种方式

- 互斥量（Mutex）：采用**互斥对象机制**，只有拥有互斥对象的线程才有访问公共资源的权限。因为**互斥对象只有一个**，所以可以保证公共资源不会被多个线程同时访问。比如 Java 中的 **synchronized** 关键词和各种 **Lock** 都是这种机制。
- **信号量（Semphares）**：它**允许同一时刻多个线程访问同一资源**，但是需要控制同一时刻访问此资源的**最大线程数量**。
- **事件(Event)** ：Wait/Notify 通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作

- **使用信号量实现生产者-消费者问题**

问题描述：使用一个缓冲区来保存物品，只有缓冲区没有满，生产者才可以放入物品；只有缓冲区不为空，消费者才可以拿走物品。

因为缓冲区属于临界资源，因此需要使用一个互斥量 mutex 来控制对缓冲区的互斥访问。

为了同步生产者和消费者的行为，需要记录缓冲区中物品的数量。数量可以使用信号量来进行统计，这里需要使用两个信号量：empty 记录空缓冲区的数量，full 记录满缓冲区的数量。其中，empty 信号量是在生产者进程中使用，当 empty 不为 0 时，生产者才可以放入物品；full 信号量是在消费者进程中使用，当 full 信号量不为 0 时，消费者才可以取走物品。

注意，**不能先对缓冲区进行加锁，再测试信号量**。也就是说，不能先执行 down(mutex) 再执行 down(empty)。如果这么做了，那么可能会出现这种情况：生产者对缓冲区加锁后，执行 down(empty) 操作，发现 empty = 0，此时生产者睡眠。消费者不能进入临界区，因为生产者对缓冲区加锁了，消费者就无法执行 up(empty) 操作，empty 永远都为 0，导致生产者永远等待下，不会释放锁，消费者因此也会永远等待下去。

```c
#define N 100
typedef int semaphore;
semaphore mutex = 1;
semaphore empty = N;
semaphore full = 0;

void producer() {
    while(TRUE) {
        int item = produce_item();
        down(&empty);
        down(&mutex);
        insert_item(item);
        up(&mutex);
        up(&full);
    }
}

void consumer() {
    while(TRUE) {
        down(&full);
        down(&mutex);
        int item = remove_item();
        consume_item(item);
        up(&mutex);
        up(&empty);
    }
}
```

## 3. 内存管理

### 3.1 内存管理介绍

操作系统的内存管理主要负责内存的分配与回收（malloc 函数：申请内存，free 函数：释放内存）；内存空间的扩展（实现虚拟性）；地址转换即将逻辑地址转换成相应的物理地址；存储保护即保证各进程在自己的内存空间内运行，不会越界访问。

### 3.2 常见内存管理机制

- **连续分配管理方式**

  - **固定分区分配**：。将内存分为几个固定大小的块，每个块中只包含一个进程。

    **内碎片**：**每个块中未被利用的空间**

  - **动态分区分配**：根据进程大小动态分配分区大小。

    **外碎片**：**每个块间因太小无法被利用的空间**

    - 空闲分区以地址递增的次序排列

      **首次适应算法（First Fit）**；**下次适应算法（Next Fit）**

    - 空闲分区以容量递增的次序排列

      **最佳适应算法（Best Fit）**；**最坏适应算法（Worse Fit）**

- **非连续分配管理方式**

  - **页式管理**：把主存分为大小相等且固定的一页一页的形式，页较小，较于块式管理的划分力度更大，提高了内存利用率减少了碎片。页式管理通过页表对应逻辑地址和物理地址。

    置换淘汰算法：

    - **最佳置换算法OPT**

      - 淘汰以后永不使用的，或是在最长(未来)时间内不再被访问的页面。

      - 理想算法，无法真的实现，可以用来衡量其他置换算法的优劣。

    - **选进选出FIFO**（First In First Out）
      - 每次淘汰最先调入内存的页面。实现方式只需要一个队列即可。将所有放入内存的页面排成一队，每次淘汰队首页面。
    - **最不经常使用LFU**（Least Frequently Used）
      - 在页表中给每一页增设一个**访问计数器**，每次需要淘汰时淘汰到当前时间为止，被访问次数最少的那一页。
    - **最近最久未使用LRU**（Least Recently Used）
      - **需要淘汰一个页面时，总是选择在最近一段时间内最久不用的页面予以淘汰**
    - **时钟置换算法Clock**
      - 当页面被装入内存时，或是内存中的页面被访问时，访问位被置为1。若内存已被装满，那就需要淘汰一个页面，于是指针就从上一个被淘汰的页面的下一个位置开始，顺序去遍历这循环列表，访问到访问位为1的页面时，就把该访问位置0，继续遍历，只要遇到访问位为0的页面时，淘汰该页面。

  - **段式管理**：页式管理虽然提高了内存利用率，但是页式管理其中的页并无任何实际意义。 段式管理把主存分为一段段的，每一段的空间又要比一页的空间小很多 。但是，最重要的是段是有实际意义的，每个段定义了一组逻辑信息，例如,有主程序段 MAIN、子程序段 X、数据段 D 及栈段 S 等。 段式管理通过段表对应逻辑地址和物理地址。

  - **段页式管理**：段页式存储管理方式即先将用户程序分成若干个段，再把每个段分成若干个页，并为每一个段赋予一个段名。也就是说 **段页式管理机制** 中段与段之间以及段的内部的都是离散的。

### 3.3 分页机制与分段机制的异同

- 相同：
  - 分页机制和分段机制都可以提高内存利用率，减少内存碎片。
  - 都采用离散分配方式，但是每个页端内的内存是连续的。
  - 都通过地址映射机构来实现地址变换

- 不同:
  - 页是信息的物理单位，分页是为了实现离散分配方式，以减少内存的外零头，提高内存的利用率。或言，分页仅是由于系统管理的需要，而不是用户的需要。段是信息的逻辑单位，它含有一组其意义相对完整的信息。分段的目的是为了更好地满足用户的需要。

  - 页的大小固定且由系统决定，把逻辑地址划分为页号和页内地址两部分，是由机器硬件实现的。段的长度不固定，且决定于用户所编写的程序，通常由编译系统在对源程序进行编译时根据信息的性质来划分。

  - 页式系统地址空间是一维的，即单一的线性地址空间，程序员只需利用一个标识符，即可表示一个地址。分段的作业地址空间是二维的，程序员在标识一个地址时，既需给出段名，又需给出段内地址。

    ![段表寻址过程](https://raw.githubusercontent.com/Moxiansheng/practiceCoding/master/img/20210116133627)

### 3.4 页表管理

- **虚拟地址到物理地址的转换要快。**

- **解决虚拟地址空间大，页表也会很大的问题。**

#### 3.4.1 快表

​		为了解决虚拟地址到物理地址的转换速度，操作系统在 **页表方案** 基础之上引入了 **快表** 来加速虚拟地址到物理地址的转换。我们可以把快表理解为一种特殊的高速缓冲存储器（Cache），其中的内容是页表的一部分或者全部内容。作为页表的 Cache，它的作用与页表相似，但是提高了访问速率。由于采用页表做地址转换，读写内存数据时 CPU 要访问两次主存。有了快表，有时只要访问一次高速缓冲存储器，一次主存，这样可加速查找并提高指令执行速度。

使用快表之后的地址转换流程是这样的：

1. 根据虚拟地址中的页号查快表；
2. 如果该页在快表中，直接从快表中读取相应的物理地址；
3. 如果该页不在快表中，就访问内存中的页表，再从页表中得到物理地址，同时将页表中的该映射表项添加到快表中；
4. 当快表填满后，又要登记新页时，就按照一定的淘汰策略淘汰掉快表中的一个页。

#### 3.4.2 多级页表

​		为了避免把全部页表一直放在内存中占用过多空间，特别是那些根本就不需要的页表就不需要保留在内存中。多级页表属于时间换空间的典型场景。

如何节约内存：

- 二级页表可以不存在

  ​		单级页表中，假如虚拟地址在页表中找不到对应的页表项，计算机系统就不能工作了。所以页表一定要覆盖全部虚拟地址空间，也就无法节约内存。（无Plan B，Plan A要全包全揽）

  ​		分级页表中，如果某个一级页表的页表项没有被用到，也就不需要创建这个页表项对应的二级页表了，即可以在需要时才创建二级页表。（有Plan B，虽然真碰到才做出Plan B细节）

- 二级页表可以不在主存

  ​		虚拟内存地址存在着局部性，那么负责映射虚拟内存地址的页表项也存在着局部性。这样就可以将很少的一部分二级页表放在内存中，其余的二级页表放在磁盘中，需要时再调入。

### 3.5 逻辑（虚拟）地址和物理地址

- 逻辑（虚拟）地址：由操作系统决定，在上层看来是一系列连续的地址。
- 物理地址：指的是真实物理内存中地址，更具体一点来说就是内存地址寄存器中的地址。物理地址是内存单元真正的地址。

### 3.6 CPU寻址

- 现代处理器使用的是一种称为 **虚拟寻址(Virtual Addressing)** 的寻址方式。**使用虚拟寻址，CPU 需要将虚拟地址翻译成物理地址，这样才能访问到真实的物理内存。** 

- 实际上完成虚拟地址转换为物理地址转换的硬件是 CPU 中含有一个被称为 **内存管理单元（Memory Management Unit, MMU）** 的硬件。
- [TLB](https://zhuanlan.zhihu.com/p/108425561?utm_source=wechat_timeline) 在CPU和快表中又加了一层，快表是CPU和内存间加的一层。

## **4. 虚拟内存**

### 4.1 什么是虚拟内存

- **虚拟内存** 使得应用程序认为它拥有连续的可用的内存（一个连续完整的地址空间），而实际上，它通常是被分隔成多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。与没有使用虚拟内存技术的系统相比，使用这种技术的系统使得大型程序的编写变得更容易，对真正的物理内存（例如 RAM）的使用也更有效率。

- **虚拟内存为每个进程提供一个一致的、私有的地址空间，它让每个进程产生一种自己在独享主存的错觉（每个进程拥有一片连续完整的内存空间）**。这会更加有效地管理内存并减少出错。

### 4.2 局部性原理

- **时间局部性** ：如果程序中的某条指令一旦执行，不久以后该指令可能再次执行；如果某数据被访问过，不久以后该数据可能再次被访问。产生时间局部性的典型原因，是由于在程序中存在着大量的循环操作。
- **空间局部性** ：一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也将被访问，即程序在一段时间内所访问的地址，可能集中在一定的范围之内，这是因为指令通常是顺序存放、顺序执行的，数据也一般是以向量、数组、表等形式簇聚存储的。
- 时间局部性是通过将近来使用的指令和数据保存到高速缓存存储器中，并使用高速缓存的层次结构实现。
- 空间局部性通常是使用较大的高速缓存，并将预取机制集成到高速缓存控制逻辑中实现。
- 虚拟内存技术就是建立 “内存一外存”的两级存储器的结构，利用局部性原理实现高速缓存。

### 4.3 虚拟存储器

​		基于局部性原理，在程序装入时，可以将程序的一部分装入内存，而将其他部分留在外存，就可以启动程序执行。由于外存往往比内存大很多，所以我们运行的软件的内存大小实际上是可以比计算机系统实际的内存大小大的。在程序执行过程中，当所访问的信息不在内存时，由操作系统将所需要的部分调入内存，然后继续执行程序。另一方面，操作系统将内存中暂时不使用的内容换到外存上，从而腾出空间存放将要调入内存的信息。这样，计算机好像为用户提供了一个比实际内存大的多的存储器——**虚拟存储器**。

### 4.4 虚拟内存的技术实现

#### 4.4.1 请求分页存储管理

​		建立在分页管理之上，为了支持虚拟存储器功能而增加了请求调页功能和页面置换功能。请求分页是目前最常用的一种实现虚拟存储器的方法。请求分页存储管理系统中，在作业开始运行之前，仅装入当前要执行的部分段即可运行。假如在作业运行的过程中发现要访问的页面不在内存，则由处理器通知操作系统按照对应的页面置换算法将相应的页面调入到主存，同时操作系统也可以将暂时不用的页面置换到外存中。

#### 4.4.2 请求分段存储管理

​		建立在分段存储管理之上，增加了请求调段功能、分段置换功能。请求分段储存管理方式就如同请求分页储存管理方式一样，在作业开始运行之前，仅装入当前要执行的部分段即可运行；在执行过程中，可使用请求调入中断动态装入要访问但又不在内存的程序段；当内存空间已满，而又需要装入新的段时，根据置换功能适当调出某个段，以便腾出空间而装入新的段。

#### 4.4.3 请求段页式存储管理

#### 4.4.4 对比分页与分页存储管理

​		请求分页存储管理建立在分页管理之上。他们的根本区别是是否将程序全部所需的全部地址空间都装入主存。请求分页存储管理不要求将作业全部地址空间同时装入主存。基于这一点，请求分页存储管理可以提供虚存，而分页存储管理却不能提供虚存。

#### 4.4.5 实现条件

1. **一定容量的内存和外存**：在载入程序的时候，只需要将程序的一部分装入内存，而将其他部分留在外存，然后程序就可以执行了；
2. **缺页中断**：如果**需执行的指令或访问的数据尚未在内存**（称为缺页或缺段），则由处理器通知操作系统将相应的页面或段**调入到内存**，然后继续执行程序；
3. **虚拟地址空间** ：逻辑地址到物理地址的变换。

## 5. 死锁

### 5.1 必要条件

- 互斥：每个资源要么已经分配给了一个进程，要么就是可用的。
- 占有和等待：已经得到了某个资源的进程可以再请求新的资源。
- 不可抢占：已分配给一个进程的资源不能强制性地被抢占，它只能被占有它的进程显式地释放。
- 环路等待：有两个或者两个以上的进程组成一条环路，该环路中的每个进程都在等待下一个进程所占有的资源。

### 5.2 处理方法

#### 5.2.1 鸵鸟策略

​		因为解决死锁问题的代价很高，因此鸵鸟策略这种不采取任务措施的方案会获得更高的性能。当发生死锁时不会对用户造成多大影响，或发生死锁的概率很低，可以采用鸵鸟策略。

#### 5.2.2 死锁检测与死锁回复

不试图阻止死锁，而是当检测到死锁发生时，采取措施进行恢复。

##### 5.2.2.1 每种类型一个资源的死锁检测

通过检测有向图是否存在环来实现，从一个节点出发进行深度优先搜索，对访问过的节点进行标记，如果访问了已经标记的节点，就表示有向图存在环，也就是检测到死锁的发生。

##### 5.2.2.2 每种类型多个资源的死锁检测

![](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/e1eda3d5-5ec8-4708-8e25-1a04c5e11f48.png)

上图中，有三个进程四个资源，每个数据代表的含义如下：

- E 向量：资源总量
- A 向量：资源剩余量
- C 矩阵：每个进程所拥有的资源数量，每一行都代表一个进程拥有资源的数量
- R 矩阵：每个进程请求的资源数量

进程 P1 和 P2 所请求的资源都得不到满足，只有进程 P3 可以，让 P3 执行，之后释放 P3 拥有的资源，此时 A = (2 2 2 0)。P2 可以执行，执行后释放 P2 拥有的资源，A = (4 2 2 1) 。P1 也可以执行。所有进程都可以顺利执行，没有死锁。

算法总结如下：

每个进程最开始时都不被标记，执行过程有可能被标记。当算法结束时，任何没有被标记的进程都是死锁进程。

1. 寻找一个没有标记的进程 Pi，它所请求的资源小于等于 A。
2. 如果找到了这样一个进程，那么将 C 矩阵的第 i 行向量加到 A 中，标记该进程，并转回 1。
3. 如果没有这样一个进程，算法终止。

##### 5.2.2.3 死锁恢复

- 利用抢占恢复
- 利用回滚恢复
- 通过杀死进程恢复

#### 5.2.3 死锁预防

在程序运行之前预防发生死锁。

##### 5.2.3.1. 破坏互斥条件

例如打印机技术允许若干个进程同时输出，唯一真正请求物理打印机的进程是打印机守护进程。

##### 5.2.3.2. 破坏占有和等待条件

一种实现方式是规定所有进程在开始执行前请求所需要的全部资源。

##### 5.2.3.3. 破坏不可抢占条件

##### 5.2.3.4. 破坏环路等待

给资源统一编号，进程只能按编号顺序来请求资源。

#### 5.2.4 死锁避免

在程序运行时避免发生死锁。

定义：如果没有死锁发生，并且即使所有进程突然请求对资源的最大需求，也仍然存在某种调度次序能够使得每一个进程运行完毕，则称该状态是安全的。

安全状态的检测与死锁的检测类似，因为安全状态必须要求不能发生死锁。

## 6. 设备管理

### 6.1 磁盘结构

- 盘面（Platter）：一个磁盘有多个盘面；
- 磁道（Track）：盘面上的圆形带状区域，一个盘面可以有多个磁道；
- 扇区（Track Sector）：磁道上的一个弧段，一个磁道可以有多个扇区，它是最小的物理储存单位，目前主要有 512 bytes 与 4 K 两种大小；
- 磁头（Head）：与盘面非常接近，能够将盘面上的磁场转换为电信号（读），或者将电信号转换为盘面的磁场（写）；
- 制动手臂（Actuator arm）：用于在磁道之间移动磁头；
- 主轴（Spindle）：使整个盘面转动。

### 6.2 磁盘调度算法

读写一个磁盘块的时间的影响因素有：

- 寻道时间（制动手臂移动，使得磁头移动到适当的磁道上）
- 旋转时间（主轴转动盘面，使得磁头移动到适当的扇区上）
- 实际的数据传输时间

其中，寻道时间最长，因此磁盘调度的主要目标是使磁盘的平均寻道时间最短。

#### 6.2.1. 先来先服务

> FCFS, First Come First Served

按照磁盘请求的顺序进行调度。

优点是公平和简单。缺点也很明显，因为未对寻道做任何优化，使平均寻道时间可能较长。

#### 6.2.2. 最短寻道时间优先

> SSTF, Shortest Seek Time First

优先调度与当前磁头所在磁道距离最近的磁道。

虽然平均寻道时间比较低，但是不够公平。如果新到达的磁道请求总是比一个在等待的磁道请求近，那么在等待的磁道请求会一直等待下去，也就是出现饥饿现象。具体来说，两端的磁道请求更容易出现饥饿现象。

#### 6.2.3 电梯算法

> SCAN

电梯总是保持一个方向运行，直到该方向没有请求为止，然后改变运行方向。

电梯算法（扫描算法）和电梯的运行过程类似，总是按一个方向来进行磁盘调度，直到该方向上没有未完成的磁盘请求，然后改变方向。

因为考虑了移动方向，因此所有的磁盘请求都会被满足，解决了 SSTF 的饥饿问题。

## 7. 文件管理

### 7.1 I/O

- 一个输入操作通常包括两个阶段：
  - 等待数据准备好
  - 从内核向进程复制数据

- I/O控制方式演化
  - CPU直接控制外围设备；
  - 增加了控制器或I/O部件，CPU使用非中断的可编程I/O；
  - 增加控制器或I/O部件，CPU使用中断的可编程I/O；
  - I/O部件通过DMA直接控制存储器；
  - I/O部件增强为一个单独的处理器，有专门为I/O设计的指令集；CPU指导I/O处理器执行内存中的一个I/O程序。
  - I/O部件有自己的局部存储器（驱动程序，其本身就是一台计算机）。

------

### 系统调用接口与应用编程接口

- **系统调用（System Call）接口**

  系统调用接口是操作系统(OS)内核与上层应用进程(APP)进行交互通信的唯一接口，通过这个接口，用户可以访问OS内核空间。

- **应用编程接口（Application Programming Interface,API）**

  应用编程接口API是一些预定义的函数，跟内核没有必然联系，提供APP与开发人员基于软件或者硬件以便访问一组程序的能力，这种情况无需链接内部实现细节。

- 两者区别

  - **API是一个提供给应用程序的接口，一组函数，是与程序员进行直接交互的。 **
  - **系统调用则不与程序员进行交互的，它根据API函数，通过一个软中断机制向内核提交请求，以获取内核服务的接口。 **
  - **并不是所有的API函数都一一对应一个系统调用，有时，一个API函数会需要几个系统调用来共同完成函数的功能，甚至还有一些API函数不需要调用相应的系统调用（因此它所完成的不是内核提供的服务）**